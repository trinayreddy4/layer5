<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Layer5 Technical Posts]]></title><description><![CDATA[Expect more from your infrastructure. Cloud native, open source software for your cloud native infrastructure and applications. Allowing developers to focus on business logic, not infrastructure concerns. Empowering operators to confidently run modern infrastructure.]]></description><link>https://layer5.io</link><generator>GatsbyJS</generator><lastBuildDate>Wed, 15 Nov 2023 01:08:42 GMT</lastBuildDate><item><title><![CDATA[Navigating Hacktoberfest]]></title><description><![CDATA[How to have a great Hacktoberfest experience and get the most out of participating]]></description><link>https://layer5.io/blog/open-source/navigating-hacktoberfest</link><guid isPermaLink="false">https://layer5.io/blog/open-source/navigating-hacktoberfest</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Thu, 28 Sep 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/7e7878515bc5a64e27221318931fe2c6/layer5-hacktoberfest-2023.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;As the leaves begin to turn and the air grows crisp, it can only mean one thing: &lt;a href=&quot;https://hacktoberfest.com&quot;&gt;Hacktoberfest&lt;/a&gt; is here! This annual celebration of open source, hosted by Digital Ocean, invites contributors from all over the world to participate in a month-long extravaganza of code contributions. While the allure of limited-edition swag may be enticing, it&amp;#x27;s essential to approach Hacktoberfest with a mindset focused on quality, respect for maintainers, and a commitment to long-term community engagement.&lt;/p&gt;&lt;p&gt;Layer5 has a long history of participating in Hacktoberfest. 2023 is no different. Our annual &lt;a href=&quot;/community/events/hacktoberfest-prep-2023-easing-into-cncf-open-source-projects&quot;&gt;Hacktoberfest kickoff and prep event&lt;/a&gt; (be sure to join) is tomorrow.&lt;/p&gt;&lt;h3&gt;1. Purposeful Participation: Beyond Swag Chasing and Profile Building&lt;/h3&gt;&lt;p&gt;Before you embark on your Hacktoberfest journey, take a moment to reflect on your motivation. Are you here solely for the swag, just for the green boxes in your GitHub profile, or do you genuinely want to make a meaningful contribution to a project, learn, grow, and make new friends in the process? Embrace the opportunity to forge lasting connections and dive deeper into topics that resonate with you. &lt;/p&gt;&lt;h3&gt;2. Quality Over Quantity: Making a Lasting Impact&lt;/h3&gt;&lt;p&gt;While a flurry of pull requests may be impressive, maintainers value contributions that add genuine value. Think beyond code and consider how your unique skills—whether in design, organization, or other areas can enrich the project. Open Source thrives on meaningful contributions, so let&amp;#x27;s aim to make a tangible difference, rather than settling for mediocrity. You will grow in the process and so will the project.&lt;/p&gt;&lt;div class=&quot;blockquotestyle__BlockquoteStyle-sc-1yeq4hm-0 bwvwmu blockquote&quot;&gt;&lt;div class=&quot;blockquote-wrapper&quot;&gt;&lt;div class=&quot;blockquote-container&quot;&gt;&lt;h1 class=&quot;blockquote-quote&quot;&gt;When you are clear about what motivates you, each contribution you make will help you achieve your goals, because you will be working on projects that are aligned with your values.&lt;/h1&gt;&lt;h4 class=&quot;blockquote-person&quot;&gt;— Lee Calcote&lt;/h4&gt;&lt;h5 class=&quot;blockquote-title&quot;&gt;&lt;/h5&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h3&gt;3. Guidelines Aren&amp;#x27;t Optional: Respecting the Playbook&lt;/h3&gt;&lt;p&gt;That CONTRIBUTING.md file? It&amp;#x27;s not there for decoration. Treat it as your playbook, providing guidance for equitable collaboration. Ignoring these guidelines is akin to rearranging someone&amp;#x27;s furniture without permission. Established protocols are crucial, especially in projects with numerous contributors. They help navigate the intricacies of collaborative development. As an example, there is a full set of contributig docs written for Meshery - one for each component:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-gitflow&quot;&gt;Contributing to Meshery using git&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/meshery-windows&quot;&gt;Setting up Meshery Development Environment on Windows&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/build-and-release&quot;&gt;Contributing to Meshery Build and Release (CI)&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-cypress&quot;&gt;Contributing to Meshery&amp;#x27;s End-to-End Tests using Cypress&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-adapters&quot;&gt;Contributing to Meshery Adapters&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-docker-extension&quot;&gt;Contributing to Meshery Docker Extension&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-server&quot;&gt;Contributing to Meshery Server&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-models&quot;&gt;Contributing to Meshery Models&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-error&quot;&gt;How to write MeshKit compatible errors&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-ui&quot;&gt;Contributing to Meshery UI&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-ui-notification-center&quot;&gt;Contributing to Meshery UI - Notification Center&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-docs&quot;&gt;Contributing to Meshery Docs&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-cli&quot;&gt;Contributing to Meshery CLI&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;/project/contributing/contributing-cli-guide&quot;&gt;Meshery CLI Contributing Guidelines&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4. Upholding a Safe Environment: The Code of Conduct&lt;/h3&gt;&lt;p&gt;Respect, collaboration, and kindness are the bedrock of Open Source. The Code of Conduct is non-negotiable, ensuring a secure and inclusive space for all contributors. Reporting mechanisms are in place to uphold these principles. As contributors, it is our duty to champion a culture of respect and security, nurturing an environment where creativity and innovation flourish. The &lt;a href=&quot;/community/handbook&quot;&gt;Layer5 Community Handbook&lt;/a&gt; offers an excellent reference for our community&amp;#x27;s culture norms and practices.&lt;/p&gt;&lt;h3&gt;5. Engaging Beyond Code: Fostering Holistic Development&lt;/h3&gt;&lt;p&gt;Don&amp;#x27;t confine yourself to a GitHub profile. Engage in meaningful discussions, participate in webinars, and &lt;a href=&quot;https://discuss.layer5.io&quot;&gt;open discussions&lt;/a&gt;. Be a mentor and seek mentorship. Open Source offers a wealth of opportunities for comprehensive growth. While coding skills undoubtedly benefit, the real lessons often lie in understanding people and their diverse perspectives.&lt;/p&gt;&lt;h3&gt;6. Compassion Over Code: Recognizing Maintainer Burnout&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;/community/handbook/repository-overview&quot;&gt;Maintainers&lt;/a&gt; are the unsung heroes of the open-source world, often overwhelmed by the Hacktoberfest influx. Your seemingly &amp;quot;simple&amp;quot; pull request may be the tipping point. Recognize their efforts and respect their capacity. Some projects may not actively seek new contributions, and that&amp;#x27;s perfectly valid. Begin by identifying projects explicitly welcoming newcomers, tagged with &lt;a href=&quot;https://github.com/issues?q=is%3Aopen+is%3Aissue+archived%3Afalse+org%3Alayer5io+org%3Alayer5labs+org%3Ameshery+org%3Aservice-mesh-performance+org%3Aservice-mesh-patterns+label%3A%22help+wanted%22+&quot;&gt;&amp;quot;good first issue&amp;quot;&lt;/a&gt; or &lt;a href=&quot;https://github.com/issues?q=is%3Aopen+is%3Aissue+archived%3Afalse+org%3Alayer5io+org%3Ameshery+org%3Aservice-mesh-performance+org%3Aservice-mesh-patterns+label%3A%22help+wanted%22+&quot;&gt;&amp;quot;help wanted&amp;quot;&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;7. The Virtue of Patience: Embracing the Long Game&lt;/h3&gt;&lt;p&gt;Open source is a marathon, not a sprint. Feedback may take time, and collaboration may be challenging. Patience is the glue that holds this ecosystem together. Cultivate it as a fundamental habit in your contributor journey. The Layer5 &lt;a href=&quot;/community/members&quot;&gt;community members&lt;/a&gt; invest time, patience, understanding and offer endless hours of support to our contributors. Stick around and benefit. In turn, offer to help others. There&amp;#x27;s little better way to learn, than through teaching.&lt;/p&gt;&lt;h3&gt;8. Humility and Gratitude: The Essence of Meaningful Contributions&lt;/h3&gt;&lt;p&gt;Remember, a meaningful contribution is its own reward. Swag and a profile boost is a delightful bonus, not the end goal. Celebrate your progress, no matter how small, and learn from your experiences. As you recognize that you are part of a much larger movement, we &lt;a href=&quot;/blog/community/layer5-recognition-program&quot;&gt;recognize our contributors and users milestones&lt;/a&gt; each step of the way. Earn any number of &lt;a href=&quot;https://badges.layer5.io&quot;&gt;Layer5 badges&lt;/a&gt; as you grow with the community.&lt;/p&gt;&lt;h3&gt;9. Earn a Badge&lt;/h3&gt;&lt;p&gt;Earn a Hacktoberfest Contributor badge by contributing to Layer5 projects during this Hacktoberfest.&lt;/p&gt;&lt;img src=&quot;/static/hacktoberfest-contributor-0c87d6b9edd34f4c7ac267254ac44dc4.png&quot; style=&quot;width:250px&quot;/&gt;&lt;h1&gt;Join Layer5&amp;#x27;s Hacktoberfest Event&lt;/h1&gt;&lt;figure class=&quot;imgWithCaption&quot; style=&quot;width:80%&quot;&gt;&lt;a href=&quot;/community/events/hacktoberfest-prep-2023-easing-into-cncf-open-source-projects&quot;&gt;&lt;img src=&quot;/static/hacktoberfest-2023-with-layer5-d75ad4f9d2094005dd4e683555130e23.png&quot;/&gt;&lt;/a&gt;&lt;figcaption style=&quot;display:flex;gap:2rem&quot;&gt;&lt;div&gt;&lt;strong&gt;&lt;a href=&quot;/community/events/hacktoberfest-prep-2023-easing-into-cncf-open-source-projects&quot;&gt;Hacktoberfest Prep 2023: Easing into CNCF Open Source Projects&lt;/a&gt;&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;DATE: September 29, 2023&lt;/li&gt;&lt;li&gt;TIME: 3PM UTC | 10AM Central | 8:30PM IST&lt;/li&gt;&lt;li&gt;EVENT: &lt;a href=&quot;https://meet.layer5.io/community&quot;&gt;Zoom&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;strong&gt; Open GitHub Issues by Label:&lt;/strong&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/issues?q=is%3Aopen+is%3Aissue+archived%3Afalse+org%3Alayer5io+org%3Ameshery+org%3Aservice-mesh-performance+org%3Aservice-mesh-patterns+label%3A%22hacktoberfest%22+&quot;&gt;&amp;quot;hacktoberfest&amp;quot; issues&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/issues?q=is%3Aopen+is%3Aissue+archived%3Afalse+org%3Alayer5io+org%3Ameshery+org%3Aservice-mesh-performance+org%3Aservice-mesh-patterns+label%3A%22help+wanted%22+&quot;&gt;&amp;quot;help wanted&amp;quot; issues&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/issues?q=is%3Aopen+is%3Aissue+archived%3Afalse+org%3Alayer5io+org%3Alayer5labs+org%3Ameshery+org%3Aservice-mesh-performance+org%3Aservice-mesh-patterns+label%3A%22help+wanted%22+&quot;&gt;&amp;quot;good first issue&amp;quot; issues&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Hacktoberfest is an opportunity for transformation, a time when contributors and maintainers can connect on a deeper level. Let&amp;#x27;s be the contributors that maintainers celebrate, rather than dread. Whether maintainers actively seek contributions or focus on internal tasks, respect their choices. Remember, we&amp;#x27;re all weaving the rich tapestry of the open-source community, and together, we&amp;#x27;re contributing to something far greater than a month-long treasure hunt. So, dive in, make a splash, and keep coming back for more than just the loot. Happy Hacking!&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Unlocking the Power of WebAssembly in Service Mesh Management]]></title><description><![CDATA[This is a short summary of my blog post. This text will show in the blog's list view and in community newsletters.]]></description><link>https://layer5.io/blog/partners/unlocking-the-power-of-webassembly-in-service-mesh-management</link><guid isPermaLink="false">https://layer5.io/blog/partners/unlocking-the-power-of-webassembly-in-service-mesh-management</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Tue, 05 Sep 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/06fcccd9678b694969c3285517e791ac/intel-grey.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Welcome to another exciting edition of Feature Friday Bulletin, where we unveil the latest enhancements to Meshery, your go-to service mesh management tool. This week, we&amp;#x27;re thrilled to announce a groundbreaking collaboration between Layer5 and Intel, bringing you a suite of service mesh management features tailored for WebAssembly-based network traffic management filters in Envoy, the sidecar proxy used in the data plane of Istio. These new features open up a world of possibilities for your service mesh architecture.&lt;/p&gt;&lt;img src=&quot;https://mcusercontent.com/6b50be5aea3dfe1fd4c041d80/images/c4a4d061-a42d-5373-f789-cc29a21b3d5c.png&quot; width=&quot;15%&quot; style=&quot;margin:1rem 1rem 1rem 0rem&quot;/&gt;&lt;h2&gt;Seamless WASM Envoy Filter Management&lt;/h2&gt;&lt;p&gt;With this collaboration, we&amp;#x27;re introducing powerful features that simplify the management of Envoy WASM filters via Meshery:&lt;/p&gt;&lt;h3&gt;Meshery UI and CLI Integration&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Import WASM Envoy Filters&lt;/strong&gt;: Easily import your WebAssembly Envoy filters into Meshery using the intuitive UI or the command-line interface (&lt;a href=&quot;https://docs.meshery.io/reference/mesheryctl#data-plane-intelligence&quot;&gt;CLI&lt;/a&gt;).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Publish and Clone Filters&lt;/strong&gt;: Share your filters with the community by publishing them in the &lt;a href=&quot;https://meshery.io/catalog&quot;&gt;Meshery Catalog&lt;/a&gt; and make it effortless for others to clone them.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Download WASM Binaries&lt;/strong&gt;: Access and download WebAssembly binaries directly from &lt;a href=&quot;https://meshery.layer5.io/&quot;&gt;Layer5 Cloud&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Efficient Data Plane Design&lt;/strong&gt;: Seamlessly design and deploy Istio and Envoy data planes using &lt;a href=&quot;https://layer5.io/cloud-native-management/meshmap&quot;&gt;MeshMap&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Contribute to Open Source&lt;/strong&gt;: Get involved with the service mesh community by contributing to any of the 7 open-source &lt;a href=&quot;https://github.com/layer5io/wasm-filters&quot;&gt;wasm-filters&lt;/a&gt; developed by Layer5.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Collaboration and Engagement&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;:star2: &lt;strong&gt;Support Your Favorites&lt;/strong&gt;: Encourage collaboration by starring your &lt;a href=&quot;https://github.com/meshery/meshery&quot;&gt;favorite repository&lt;/a&gt; on GitHub.&lt;/li&gt;&lt;li&gt;:playground_slide: &lt;strong&gt;Hands-On Experience&lt;/strong&gt;: Experience these features firsthand in the &lt;a href=&quot;https://playground.meshery.io/&quot;&gt;Meshery Playground&lt;/a&gt; by accessing version v0.6.109.&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://mcusercontent.com/6b50be5aea3dfe1fd4c041d80/images/a07ef29a-4cf8-986e-9bd3-78db7dc00ce1.png&quot; width=&quot;15%&quot; style=&quot;margin:1rem 1rem 1rem 0rem&quot;/&gt;&lt;h2&gt;Envoy WASM Filter Management&lt;/h2&gt;&lt;p&gt;We&amp;#x27;ve revamped the management of Envoy WASM filters in Meshery with several enhancements:&lt;/p&gt;&lt;h3&gt;Meshery Server Integration&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ New WASM Filter Component: A new component is available in the Design Configurator to simplify filter management.&lt;/li&gt;&lt;li&gt;✅ Improved Component Icon: Enhancements have been made to provide a more user-friendly experience.&lt;/li&gt;&lt;li&gt;✅ Relationship Patch Policy: A new policy has been introduced to streamline the relationship between components.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Meshery CLI Command Line&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ Import Filters: Use &lt;code&gt;mesheryctl filter import [URL | filepath]&lt;/code&gt; to effortlessly import filters.&lt;/li&gt;&lt;li&gt;✅ Delete Filters: Remove unwanted filters with &lt;code&gt;mesheryctl filter delete [filter-name | ID]&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;✅ View Filters: Gain insights into your filters using &lt;code&gt;mesheryctl filter view [filter-name | ID]&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;✅ List and Search Filters: Easily navigate filters with &lt;code&gt;mesheryctl filter list [filter-name | ID]&lt;/code&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;MeshMap Integration&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ Apply WASM Filters: Hierarchically apply filters to your Envoy configurations.&lt;/li&gt;&lt;li&gt;✅ Deploy/Undeploy Filters: Streamline the deployment and removal of filters with custom configurations.&lt;/li&gt;&lt;li&gt;✅ Enhanced Visibility: View filters within a dedicated panel and seamlessly drop them onto the canvas.&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://mcusercontent.com/6b50be5aea3dfe1fd4c041d80/images/1e9c2e71-1b3e-a132-4766-8cefdc9861d2.png&quot; width=&quot;15%&quot; style=&quot;margin:1rem 1rem 1rem 0rem&quot;/&gt;&lt;h3&gt;Meshery UI Enhancements&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ Import Filters: Import filters directly via URL or filesystem.&lt;/li&gt;&lt;li&gt;✅ Improved Browsing: Browse, search, and view filters in both grid view and table view.&lt;/li&gt;&lt;li&gt;✅ Streamlined Lists: Easily list and search filters in grid view or table view.&lt;/li&gt;&lt;li&gt;✅ Download Filters: Download filters effortlessly from the UI.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Layer5 Cloud and Catalog Integration&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ Permanent Storage and Artifact Dispersal: Ensure your filters are securely stored and widely accessible.&lt;/li&gt;&lt;li&gt;✅ Catalog Features: Import, clone, download, publish, and unpublish filters within the Meshery Catalog.&lt;/li&gt;&lt;li&gt;✅ Enhanced Privacy Controls: Manage user permissions, team ownership, and visibility for your filters.&lt;/li&gt;&lt;li&gt;✅ Content Curation: Streamline content curation with an approval flow request queue.&lt;/li&gt;&lt;li&gt;✅ On-Premises Deployment: Run Layer5 Cloud on-premises using Docker Compose or Helm Chart.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Performance Management Upgrades&lt;/h2&gt;&lt;p&gt;In addition to Envoy WASM filter management, we&amp;#x27;ve also introduced new performance management features:&lt;/p&gt;&lt;h3&gt;Meshery Server&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ Performance Profiles: Tailor your performance profiles to match your specific needs.&lt;/li&gt;&lt;li&gt;✅ SSL Certificate Support: Benefit from SSL certificate support for Fortio in the server.&lt;/li&gt;&lt;li&gt;✅ Performance Analysis Comparison: Compare performance with and without filters.&lt;/li&gt;&lt;li&gt;✅ GetNighthawk and Cloud Native Performance Releases: Access the latest releases of GetNighthawk and Cloud Native Performance.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Meshery CLI&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ Performance Profile Flags: Specify additional load generator flags with performance profiles.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Meshery UI&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ Performance Profile Flags: Customize load generator flags directly in the UI.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Cloud Native Performance Project&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ Define Performance Profiles: Clearly define your performance profiles.&lt;/li&gt;&lt;li&gt;✅ Dashboard Integration: Display test results on the dashboard.&lt;/li&gt;&lt;li&gt;✅ Intel Integration: Incorporate Intel design into scheduled workflows for Istio.&lt;/li&gt;&lt;li&gt;✅ Consolidated Performance Profiles: Streamline performance profiles on the dashboard.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;a href=&quot;http://localhost:8000/cloud-native-management/gitops&quot;&gt;MeshMap Snapshot&lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;✅ GitHub Integrated Screenshots: Capture GitHub-integrated screenshots of deployments.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This collaboration between Layer5 and Intel marks a significant milestone in service mesh management. These enhancements empower you to take full advantage of WebAssembly-based network traffic management filters in Envoy, bringing a new level of flexibility and control to your Istio deployments.&lt;/p&gt;&lt;p&gt;Stay tuned for more exciting updates in the world of service mesh management with Meshery. We can&amp;#x27;t wait to see the incredible innovations these features will inspire in your projects. Don&amp;#x27;t forget to explore these new capabilities and let us know your thoughts!&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://meshery.io/get-started&quot;&gt;Get Started with Meshery&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://play.meshery.io&quot;&gt;Try Meshery in the Cloud Native Playground&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[ Kubernetes 1.28 improves open-source cloud-native compute and networking]]></title><link>https://layer5.io/company/news/kubernetes-128-improves-open-source-cloud-native-compute-and-networking</link><guid isPermaLink="false">https://layer5.io/company/news/kubernetes-128-improves-open-source-cloud-native-compute-and-networking</guid><dc:creator><![CDATA[SDxCentral]]></dc:creator><pubDate>Wed, 16 Aug 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/3eb21de35f0cfc76476ef06c71988d63/kubernetes-1.28-improves-open-source-cloud-native-compute-and-networking.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 DQvaY&quot;&gt;&lt;p&gt;The open-source Kubernetes cloud-native platform is out with its second major update of 2023, introducing a long list of enhancements for operators in the new 1.28 release.&lt;/p&gt;&lt;p&gt;Kubernetes is an open-source project, originally started by Google and now developed under the Linux Foundation’s Cloud Native Computing Foundation (CNCF), benefiting from the contributions of more than 900 companies. Among the updates in Kubernetes 1.28 are enhancements designed to help with resiliency, including the ability to recover from non-graceful node shutdowns. There are also a series of networking-related enhancements that will enable better security and performance.&lt;/p&gt;&lt;p&gt;As is the case with every Kubernetes release, there is a theme and a code name; for Kubernetes 1.28 the name is “Planternetes.” “So in the northern hemisphere, it’s summer right now and I think the symbolism of the garden and our community goes hand in hand,” Grace Nguyen, release lead for Kubernetes 1.28, told SDxCentral. “Each of us has a very important role in the ecosystem and together we built this big, open-source project that has a lot of impact.”&lt;/p&gt;&lt;h3&gt;Networking enhancements in Kubernetes 1.28&lt;/h3&gt;Looking specifically at the networking capabilities of Kubernetes 1.28, there are a few enhancements that will also help to improve overall performance.&lt;br/&gt;&lt;br/&gt;&lt;a href=&quot;/community/members/lee-calcote/bio&quot;&gt;Lee Calcote&lt;/a&gt;, founder of &lt;a href=&quot;/about&quot;&gt;Layer5&lt;/a&gt; and a CNCF contributor, explained that one of the key networking updates is an enhancement to the kube-proxy feature that will enable better connection-draining capabilities for load balancers targeting terminating nodes.&lt;p&gt;“This enhancement improves the reliability of load balancer health checks and connection draining for terminating nodes within Kubernetes, so that kube-proxy can independently report its health regardless of the terminating state of the node,” Calcote told SDxCentral. “In this way, cloud providers in particular can be more sophisticated in ascertaining if a load balancer should target a specific node for ingress traffic or not.”&lt;/p&gt;&lt;p&gt;Also of note in Kubernetes 1.28 for networking is IPv4 to IPv6 dual-stack transition support for Kubernetes pods. Calcote explained that this enhancement allows pods to access information about both IPv4 and IPv6 addresses associated with the node they are running on, thereby enhancing their ability to adapt to dual-stack network transitions.&lt;/p&gt;&lt;p&gt;Cloud-native networking beyond Kubernetes
While Kubernetes has many built-in capabilities, extensibility of the platform is a key attribute as well.&lt;/p&gt;&lt;p&gt;Calcote explained that proxies running in Kubernetes are quite powerful and many support on-the-fly insertion or removal of traffic filters as plugins, with technologies like Envoy, Traefik, and NGINX as prime examples. He noted that each technology varies in support for the chaining of multiple filters and for the programming languages in which developers can create these filters. Envoy, in particular, supports WebAssembly (WASM)-based filters, which means that a number of different languages are supported.&lt;/p&gt;&lt;p&gt;“Kubernetes has yet to address this deeper area of network traffic management, which is where CNCF projects like &lt;a href=&quot;https://meshery.io/&quot;&gt;Meshery&lt;/a&gt; step in with WASM filter management for any Envoy proxy or Envoy-based service-mesh data plane,” he said.&lt;/p&gt;&lt;p&gt;Kubernetes 1.28 has deep roots for stability
Nguyen noted that there are some 45 enhancements in the Kubernetes 1.28 update, spanning new stable, beta and alpha capabilities.&lt;/p&gt;&lt;p&gt;Kubernetes is widely deployed on public cloud providers and is also used as the foundation of several commercial offerings, including one from IBM‘s Red Hat business unit.&lt;/p&gt;&lt;p&gt;“The latest release of Kubernetes has a number of enhancements to help increase the stability, performance and maintainability of the core platform while also augmenting workload innovation, including AI [artificial intelligence] and virtual machines,” Karena Angell, OpenShift Commons lead and senior principal product manager for Red Hat OpenShift and Hybrid Platforms, told SDxCentral.&lt;/p&gt;&lt;p&gt;Angell said Red Hat is particularly interested in the new node system memory swap support that has been added to Kubernetes 1.28 to enable better memory performance across a cluster. Additionally, she noted that the Kubernetes Job API now allows for more choices in AI model training and retraining, which is especially key for AI-driven and intelligent workloads.&lt;/p&gt;&lt;p&gt;“As Kubernetes continues to mature as a platform with release 1.28, we’re very happy to see a number of new features and tweaks that further support production stability and consistency,” Angell said. “Large and complicated jobs can now fail faster and more accurately which, while it sounds strange, contributes to better overall performance of Kubernetes in production.”&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Layer5 💚's Open Source]]></title><description><![CDATA[HashiCorp Relicensing and Layer5's Partnership]]></description><link>https://layer5.io/blog/announcements/layer5-s-open-source</link><guid isPermaLink="false">https://layer5.io/blog/announcements/layer5-s-open-source</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Fri, 11 Aug 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/72bc74d6687454f7700b4af70521f97a/layer5-open-source.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Yesterday, &lt;a href=&quot;https://www.globenewswire.com/news-release/2023/08/10/2723189/0/en/HashiCorp-adopts-the-Business-Source-License-for-future-releases-of-its-products.html&quot;&gt;HashiCorp announced a change in their source code license&lt;/a&gt; from Mozilla Public License v2.0 (MPL 2.0) to the Business Source License (BSL, or BUSL) v1.1, effective in all future releases of HashiCorp’s core products, including Terraform, Vault, Consul, Boundary, Nomad, Waypoint, Packer, and Vagrant. HashiCorp APIs, SDKs, and with almost all other libraries remaining MPLv2.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;/company/news/layer5-hashicorp-launch-service-mesh-partnership&quot;&gt;HashiCorp and Layer5 partnered&lt;/a&gt; early at the start of Layer5 and continues to be a technology partner. Layer5&amp;#x27;s projects and products are unaffected by HashiCorp relicensing their software yesterday. Layer5 stands with the open source community and with source-available HashiCorp. &lt;/p&gt;&lt;p&gt;Layer5&amp;#x27;s sprawling &lt;a href=&quot;/projects&quot;&gt;portfolio of projects&lt;/a&gt; &lt;a href=&quot;/blog/community/meshery-surpasses-1000-contributors&quot;&gt;are open source&lt;/a&gt;, pervasively using the Apache 2.0 license. Layer5 is a &lt;a href=&quot;/company/about&quot;&gt;community-first organization&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Under an open core model, we look forward to continuing to serve our customers with open source and our amazing, fast-growing &lt;a href=&quot;/community&quot;&gt;community&lt;/a&gt; at the center of our focus.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[How To Bind Kubernetes Service Account with ClusterRole]]></title><link>https://layer5.io/blog/meshery/how-to-bind-kubernetes-service-account-with-clusterrole</link><guid isPermaLink="false">https://layer5.io/blog/meshery/how-to-bind-kubernetes-service-account-with-clusterrole</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Fri, 30 Jun 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/87c3e5e43ab121617b3f31b331d94df7/blog-post.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Kubernetes provides robust RBAC (Role-Based Access Control) capabilities to manage access and authorization within a cluster. This allows you to control and restrict permissions for various resources. In this blog post, we will explore the process of binding a Kubernetes Service Account with a ClusterRole. We will also discuss how Meshery, a service mesh management tool, can be utilized to streamline the lifecycle management of Kubernetes clusters using MeshMap visual diagrams.&lt;/p&gt;&lt;h2&gt;Prerequisites&lt;/h2&gt;&lt;p&gt;Before we delve into the details, ensure that you have the following prerequisites in place:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Access to a running Kubernetes cluster.&lt;/li&gt;&lt;li&gt;&lt;code&gt;kubectl&lt;/code&gt;, the Kubernetes command-line tool, installed and configured to communicate with your cluster.&lt;/li&gt;&lt;li&gt;Meshery, the cloud native manager, installed and &lt;a href=&quot;https://docs.meshery.io/installation/quick-start&quot;&gt;set up&lt;/a&gt; on your local machine.&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Binding a Kubernetes Service Account with ClusterRole:&lt;/h2&gt;&lt;p&gt;To bind a Service Account with a ClusterRole, follow the steps outlined below:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 1: Create a Service Account&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;First, we need to create a Service Account that we will later bind to a ClusterRole. Use the following kubectl command to create a Service Account named &lt;code&gt;my-service-account&lt;/code&gt;:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sh kubectl create serviceaccount my-service-account&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;&lt;strong&gt;Step 2: Create a ClusterRole&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Next, let&amp;#x27;s create a ClusterRole that defines the desired permissions. You can either create a new ClusterRole or use an existing one. For the purpose of this example, we will create a ClusterRole named &lt;code&gt;my-cluster-role&lt;/code&gt; that has read-only access to Pods and Services:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-yaml&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; rbac.authorization.k8s.io/v1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; ClusterRole&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; my&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;role&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;pods&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;services&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;get&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;watch&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token string&quot; style=&quot;color:rgb(173, 219, 103)&quot;&gt;&amp;quot;list&amp;quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;Save the above YAML definition to a file named &lt;code&gt;clusterrole.yaml&lt;/code&gt;, and create the ClusterRole using the following command:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;bash kubectl apply -f clusterrole.yaml&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;&lt;strong&gt;Step 3: Bind the Service Account with ClusterRole&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Finally, we need to bind the Service Account &lt;code&gt;my-service-account&lt;/code&gt; with the ClusterRole &lt;code&gt;my-cluster-role&lt;/code&gt;. This can be achieved by creating a ClusterRoleBinding. Execute the following command to create the binding:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;bash kubectl create clusterrolebinding my-cluster-role-binding --clusterrole=my-cluster-role --serviceaccount=default:my-service-account&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;The above command creates a ClusterRoleBinding named &lt;code&gt;my-cluster-role-binding&lt;/code&gt; that associates the Service Account &lt;code&gt;my-service-account&lt;/code&gt; with the ClusterRole &lt;code&gt;my-cluster-role&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Verification:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To verify the successful binding, you can use the following command to check the ClusterRoleBinding:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;bash kubectl describe clusterrolebinding my-cluster-role-binding&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;br/&gt;&lt;p&gt;You should see the Service Account and ClusterRole information listed under the &lt;code&gt;Subjects&lt;/code&gt; and &lt;code&gt;RoleRef&lt;/code&gt; sections, respectively.&lt;/p&gt;&lt;h2&gt;Using Meshery and MeshMap for Kubernetes Cluster Lifecycle Management:&lt;/h2&gt;&lt;p&gt;Meshery is a powerful service mesh management tool that simplifies the management and operation of service meshes, including &lt;a href=&quot;https://layer5.io/blog/meshery/multi-cluster-kubernetes-management-with-meshery&quot; target=&quot;_blank&quot;&gt;Kubernetes clusters&lt;/a&gt;. MeshMap, a visual diagram feature of Meshery, provides a graphical representation of the service mesh components and their interactions.&lt;/p&gt;&lt;p&gt;To utilize Meshery and MeshMap for Kubernetes cluster lifecycle management, follow these steps:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 1: Install Meshery&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Refer to the official Meshery &lt;a href=&quot;https://docs.meshery.io/installation/quick-start&quot; target=&quot;_blank&quot;&gt;documentation&lt;/a&gt; to install Meshery on your local machine or within your Kubernetes cluster.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 2: Connect to Your Kubernetes Cluster&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once Meshery is installed, connect it to your Kubernetes cluster by configuring the necessary authentication and connection details.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 3: Access MeshMap&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;After successfully connecting Meshery to your Kubernetes cluster, you can access MeshMap from the &lt;a href=&quot;https://playground.meshery.io/&quot; target=&quot;_blank&quot;&gt;Meshery&lt;/a&gt; user interface. MeshMap visually represents the deployed service mesh, including service endpoints, traffic flows, and workload distribution.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 4: Visualize the Kubernetes Cluster with MeshMap&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once you have accessed Meshery and connected it to your Kubernetes cluster, follow these steps to visualize the cluster using MeshMap:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;From the Meshery user interface, navigate to the MeshMap section.&lt;/li&gt;&lt;li&gt;Select your connected Kubernetes cluster from the dropdown menu.&lt;/li&gt;&lt;li&gt;Click on the &amp;quot;Generate Map&amp;quot; button to generate a visual representation of the service mesh components and their interactions within the cluster.&lt;/li&gt;&lt;li&gt;Explore the generated MeshMap to gain insights into your Kubernetes cluster&amp;#x27;s architecture, traffic patterns, and workload distribution.&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this blog post, we have learned how to bind a Kubernetes Service Account with a ClusterRole to control access and authorization within a cluster. We have also explored how Meshery and its MeshMap feature can be used for visualizing the service mesh components and their interactions within a Kubernetes cluster. By following these steps, you can effectively manage and monitor your Kubernetes cluster&amp;#x27;s lifecycle using RBAC and visualization tools.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[HPE's Adoption of Layer5 Meshery and MeshMap]]></title><description><![CDATA[HPE uses Meshery to manage SPIRE instances]]></description><link>https://layer5.io/resources/case-study/hpes-adoption-of-meshery-and-meshmap</link><guid isPermaLink="false">https://layer5.io/resources/case-study/hpes-adoption-of-meshery-and-meshmap</guid><dc:creator><![CDATA[Layer5 Team]]></dc:creator><pubDate>Sat, 17 Jun 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/91d038ef73208e4f202eecb42cb08c1f/meshery-and-hpe.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;div class=&quot;hpestyle__HPEintro-sc-1wo7snj-1 fECvio&quot;&gt;HPE&amp;#x27;s adoption of Meshery was driven by the need to simplify Kubernetes cluster management and monitoring. Meshery is an open source cloud native management tool that provides a self-service platform for designing, visualizing, deploying, testing, and operating cloud native infrastructure.&lt;/div&gt;&lt;div style=&quot;display:flex;justify-content:center;padding:2%&quot;&gt;&lt;a href=&quot;/case-studies/hpe-adoption-of-layer5-meshery-and-meshmap.pdf&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 hAtMOp appion__btn&quot; title=&quot;Download Case Study&quot; alt=&quot;Download HPE&amp;#x27;s Adoption of Layer5 Meshery and MeshMap&quot;&gt; Download Case Study&lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;p&gt;HPE, a leading technology company specializing in enterprise infrastructure, adopted Meshery Extension to enhance their Kubernetes deployments. HPE uses Kubernetes as a primary platform to build and deploy their containerized applications. The company has a large and complex Kubernetes environment, which requires robust networking solutions for efficient communication between services.&lt;/p&gt;&lt;table class=&quot;hpestyle__HPEfacts-sc-1wo7snj-0 gdXxZZ&quot;&gt;&lt;tr&gt;&lt;td colSpan=&quot;2&quot;&gt;&lt;h4&gt;HPE FAST FACTS&lt;/h4&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;img src=&quot;data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik05IDNDNi4yMzg1OCAzIDQgNS4yMzg1OCA0IDhDNCAxMC43NjE0IDYuMjM4NTggMTMgOSAxM0MxMS43NjE0IDEzIDE0IDEwLjc2MTQgMTQgOEMxNCA1LjIzODU4IDExLjc2MTQgMyA5IDNaTTUuNSA4QzUuNSA2LjA2NyA3LjA2NyA0LjUgOSA0LjVDMTAuOTMzIDQuNSAxMi41IDYuMDY3IDEyLjUgOEMxMi41IDkuOTMzIDEwLjkzMyAxMS41IDkgMTEuNUM3LjA2NyAxMS41IDUuNSA5LjkzMyA1LjUgOFoiIGZpbGw9IiM3MjcyNzQiLz4KPHBhdGggZD0iTTQuNzUgMTQuNUMyLjEyNjY1IDE0LjUgMCAxNi42MjY2IDAgMTkuMjVWMjAuMjVDMCAyMC42NjQyIDAuMzM1Nzg2IDIxIDAuNzUgMjFDMS4xNjQyMSAyMSAxLjUgMjAuNjY0MiAxLjUgMjAuMjVWMTkuMjVDMS41IDE3LjQ1NTEgMi45NTUwNyAxNiA0Ljc1IDE2SDEzLjI1QzE1LjA0NDkgMTYgMTYuNSAxNy40NTUxIDE2LjUgMTkuMjVWMjAuMjVDMTYuNSAyMC42NjQyIDE2LjgzNTggMjEgMTcuMjUgMjFDMTcuNjY0MiAyMSAxOCAyMC42NjQyIDE4IDIwLjI1VjE5LjI1QzE4IDE2LjYyNjYgMTUuODczNCAxNC41IDEzLjI1IDE0LjVINC43NVoiIGZpbGw9IiM3MjcyNzQiLz4KPHBhdGggZD0iTTE4LjI1IDE1LjI1QzE4LjI1IDE0LjgzNTggMTguNTg1OCAxNC41IDE5IDE0LjVIMTkuMjVDMjEuODczNCAxNC41IDI0IDE2LjYyNjYgMjQgMTkuMjVWMjAuMjVDMjQgMjAuNjY0MiAyMy42NjQyIDIxIDIzLjI1IDIxQzIyLjgzNTggMjEgMjIuNSAyMC42NjQyIDIyLjUgMjAuMjVWMTkuMjVDMjIuNSAxNy40NTUxIDIxLjA0NDkgMTYgMTkuMjUgMTZIMTlDMTguNTg1OCAxNiAxOC4yNSAxNS42NjQyIDE4LjI1IDE1LjI1WiIgZmlsbD0iIzcyNzI3NCIvPgo8cGF0aCBkPSJNMTUgM0MxNC41ODU4IDMgMTQuMjUgMy4zMzU3OSAxNC4yNSAzLjc1QzE0LjI1IDQuMTY0MjEgMTQuNTg1OCA0LjUgMTUgNC41QzE2LjkzMyA0LjUgMTguNSA2LjA2NyAxOC41IDhDMTguNSA5LjkzMyAxNi45MzMgMTEuNSAxNSAxMS41QzE0LjU4NTggMTEuNSAxNC4yNSAxMS44MzU4IDE0LjI1IDEyLjI1QzE0LjI1IDEyLjY2NDIgMTQuNTg1OCAxMyAxNSAxM0MxNy43NjE0IDEzIDIwIDEwLjc2MTQgMjAgOEMyMCA1LjIzODU4IDE3Ljc2MTQgMyAxNSAzWiIgZmlsbD0iIzcyNzI3NCIvPgo8L3N2Zz4K&quot;/&gt;Full Time Employees: 60,000+&lt;/td&gt;&lt;td&gt;&lt;img src=&quot;data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMiAxQzUuOTI0ODcgMSAxIDUuOTI0ODcgMSAxMkMxIDE4LjA3NTEgNS45MjQ4NyAyMyAxMiAyM0MxOC4wNzUxIDIzIDIzIDE4LjA3NTEgMjMgMTJDMjMgNS45MjQ4NyAxOC4wNzUxIDEgMTIgMVpNMTAuMzI2OCAyLjY0Njg4QzYuMTk5MzcgMy4zODAyOSAyLjk5MzU5IDYuNzc4ODYgMi41NTIgMTFINy4yOTkwNUM3LjUzNzkzIDcuOTc5NjcgOC41ODc4OSA1LjA4OTEgMTAuMzI2OCAyLjY0Njg4Wk0xMy42NzMyIDIuNjQ2ODhDMTUuNDEyMSA1LjA4OTEgMTYuNDYyMSA3Ljk3OTY3IDE2LjcwMDkgMTFIMjEuNDQ4QzIxLjAwNjQgNi43Nzg4NiAxNy44MDA2IDMuMzgwMjkgMTMuNjczMiAyLjY0Njg4Wk0xNS4xOTU4IDExQzE0LjkzODUgOC4wMzg3NyAxMy44MjUzIDUuMjIzMzEgMTIgMi45MTU3MkMxMC4xNzQ3IDUuMjIzMzEgOS4wNjE0OCA4LjAzODc3IDguODA0MiAxMUgxNS4xOTU4Wk04Ljc2ODk5IDEyLjVIMTUuMjMxQzE1LjA2MTMgMTUuNjQzNSAxMy45Mjc3IDE4LjY0NzIgMTIgMjEuMDg0M0MxMC4wNzIzIDE4LjY0NzIgOC45Mzg3NCAxNS42NDM1IDguNzY4OTkgMTIuNVpNNy4yNjcgMTIuNUgyLjUxMjkzQzIuNzQzNzEgMTYuOTUwNiA2LjAzNzYgMjAuNTkxIDEwLjMyNjggMjEuMzUzMUM4LjQ5MjE1IDE4Ljc3NjQgNy40MjQ0IDE1LjcwMDcgNy4yNjcgMTIuNVpNMTMuNjczMiAyMS4zNTMxQzE1LjUwNzggMTguNzc2NCAxNi41NzU2IDE1LjcwMDcgMTYuNzMzIDEyLjVIMjEuNDg3MUMyMS4yNTYzIDE2Ljk1MDYgMTcuOTYyNCAyMC41OTEgMTMuNjczMiAyMS4zNTMxWiIgZmlsbD0iIzcyNzI3NCIvPgo8L3N2Zz4K&quot;/&gt;Market Presence: HPE is one of the largest technology companies globally, serving customers in over 150 countries.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;img src=&quot;data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMS42NTgxIDEuMDgyNDdDMTEuODcyOCAwLjk3MjUxMSAxMi4xMjcyIDAuOTcyNTExIDEyLjM0MTkgMS4wODI0N0wyMi41OTE5IDYuMzMyNDdDMjIuODQyNCA2LjQ2MDc4IDIzIDYuNzE4NTQgMjMgN0MyMyA3LjI4MTQ2IDIyLjg0MjQgNy41MzkyMiAyMi41OTE5IDcuNjY3NTNMMTIuMzQxOSAxMi45MTc1QzEyLjEyNzIgMTMuMDI3NSAxMS44NzI4IDEzLjAyNzUgMTEuNjU4MSAxMi45MTc1TDEuNDA4MDkgNy42Njc1M0MxLjE1NzU4IDcuNTM5MjIgMSA3LjI4MTQ2IDEgN0MxIDYuNzE4NTQgMS4xNTc1OCA2LjQ2MDc4IDEuNDA4MDkgNi4zMzI0N0wxMS42NTgxIDEuMDgyNDdaTTMuMzk1MTggN0wxMiAxMS40MDczTDIwLjYwNDggN0wxMiAyLjU5MjY2TDMuMzk1MTggN1oiIGZpbGw9IiM3MjcyNzQiLz4KPHBhdGggZD0iTTEuMDg5MDMgMTYuMzk1M0MxLjI4NDg4IDE2LjAzMDMgMS43Mzk1MyAxNS44OTMyIDIuMTA0NTIgMTYuMDg5TDExLjk5OTkgMjEuMzk4OEwyMS44OTUzIDE2LjA4OUMyMi4yNjAzIDE1Ljg5MzIgMjIuNzE0OSAxNi4wMzAzIDIyLjkxMDggMTYuMzk1M0MyMy4xMDY2IDE2Ljc2MDMgMjIuOTY5NSAxNy4yMTQ5IDIyLjYwNDUgMTcuNDEwOEwxMi4zNTQ1IDIyLjkxMDhDMTIuMTMzIDIzLjAyOTYgMTEuODY2OCAyMy4wMjk2IDExLjY0NTMgMjIuOTEwOEwxLjM5NTI5IDE3LjQxMDhDMS4wMzAzIDE3LjIxNDkgMC44OTMxODUgMTYuNzYwMyAxLjA4OTAzIDE2LjM5NTNaIiBmaWxsPSIjNzI3Mjc0Ii8+CjxwYXRoIGQ9Ik0yLjEwNDUyIDExLjA4OUMxLjczOTUzIDEwLjg5MzIgMS4yODQ4OCAxMS4wMzAzIDEuMDg5MDMgMTEuMzk1M0MwLjg5MzE4NSAxMS43NjAzIDEuMDMwMyAxMi4yMTQ5IDEuMzk1MjkgMTIuNDEwOEwxMS42NDUzIDE3LjkxMDhDMTEuODY2OCAxOC4wMjk2IDEyLjEzMyAxOC4wMjk2IDEyLjM1NDUgMTcuOTEwOEwyMi42MDQ1IDEyLjQxMDhDMjIuOTY5NSAxMi4yMTQ5IDIzLjEwNjYgMTEuNzYwMyAyMi45MTA4IDExLjM5NTNDMjIuNzE0OSAxMS4wMzAzIDIyLjI2MDMgMTAuODkzMiAyMS44OTUzIDExLjA4OUwxMS45OTk5IDE2LjM5ODhMMi4xMDQ1MiAxMS4wODlaIiBmaWxsPSIjNzI3Mjc0Ii8+Cjwvc3ZnPgo=&quot;/&gt;HPE GreenLake: HPE GreenLake is a key offering by the company, providing a flexible and scalable IT infrastructure model known as &amp;quot;everything-as-a-service.&amp;quot;&lt;/td&gt;&lt;td&gt;&lt;img src=&quot;data:image/svg+xml;base64,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&quot;/&gt;Research and Development: HPE invests significantly in research and development to drive innovation. It operates HPE Labs, which focuses on developing cutting-edge technologies and solutions for the future.&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;SPIRE is a toolchain of APIs for establishing trust between software systems across a wide variety of hosting platforms. SPIRE exposes the SPIFFE Workload API, which can attest running software systems and issue SPIFFE IDs and SVIDs to them. &lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;div class=&quot;hpestyle__HPEbenefits-sc-1wo7snj-2 bWNoXP&quot;&gt;&lt;b&gt;Meshery offers several benefits to HPE, including:&lt;/b&gt;&lt;br/&gt;✔️ Consistent service mesh management: HPE can now manage all their service meshes consistently, regardless of the underlying infrastructure or cloud provider.&lt;br/&gt;✔️ Improved observability: With Meshery&amp;#x27;s built-in visualization and observability tools, HPE can gain insights into the behavior of their service meshes, detect anomalies, and troubleshoot issues in real-time.&lt;br/&gt;✔️ Simplified testing and validation: Meshery&amp;#x27;s service mesh validation capabilities enable HPE to easily test and validate their service meshes, ensuring that they meet their performance, security, and compliance requirements.&lt;br/&gt;✔️ Enhanced security: With Meshery&amp;#x27;s security features, HPE can ensure that their service meshes are secure and compliant with their organization&amp;#x27;s security policies.&lt;/div&gt;&lt;br/&gt;&lt;p&gt;Overall, Meshery has helped HPE to streamline their integration of the identity management control plane to reduce complexity, and improve the overall reliability and performance of their Kubernetes environment. SPIFFE is a set of open-source specifications for a framework capable of bootstrapping and issuing identity to services across heterogeneous environments and organizational boundaries. The lifecycle of SPIFFE identities, SVIDs, is managed by SPIRE, a production-ready implementation of the SPIFFE APIs that performs node and workload attestation in order to securely issue SVIDs to workloads, and verify the SVIDs of other workloads, based on a predefined set of conditions.&lt;/p&gt;&lt;p&gt;&lt;b&gt;HPE&amp;#x27;s adoption of Meshery has also been enhanced by the platform&amp;#x27;s ability to integrate with other popular technologies, such as SPIRE and Istio&lt;/b&gt;&lt;/p&gt;&lt;p style=&quot;display:flex;justify-content:center;align-item:center;padding:2%&quot;&gt;&lt;img src=&quot;/static/meshery-integrations.e82003a0.svg&quot;/&gt;&lt;/p&gt;&lt;p&gt;SPIRE is an open-source project that provides a secure and scalable solution for service identity and authentication in distributed systems. HPE uses SPIRE to authenticate and authorize services in their Kubernetes environment, which ensures that only authorized services can communicate with each other.&lt;/p&gt;&lt;p&gt;Meshery&amp;#x27;s integration with SPIRE enables HPE to manage SPIRE instances, issue and revoke service certificates, and automate the management of SPIRE agents across their Kubernetes clusters. This integration ensures that HPE&amp;#x27;s service meshes are secure, and only authorized services can communicate with each other.&lt;/p&gt;&lt;div class=&quot;Inline-quotes__QuotesWrapper-sc-hv31e3-0 cRZWJU&quot;&gt;&lt;div class=&quot;quote-box&quot;&gt;&lt;h4&gt;❝ With a goal to bring workload identity and attestation to all service meshes, HPE Security Engineering uses the Meshery&amp;#x27;s Extension to deploy their cloud native infrastructure of choice and test the performance of our SPIFFE and SPIRE-based identity solution. ❞&lt;/h4&gt;&lt;hr/&gt;&lt;img src=&quot;data:image/webp;base64,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&quot;/&gt;&lt;div class=&quot;quote-source&quot;&gt;&lt;h5&gt;Maximiliano Churichi&lt;/h5&gt;&lt;p&gt;Software Engineer at HPE&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;In addition, HPE&amp;#x27;s use of Meshery has been enhanced by its integration with Istio, an open-source service mesh that provides a comprehensive solution for traffic management, security, and observability in Kubernetes environments.&lt;/p&gt;&lt;p&gt;Meshery&amp;#x27;s integration with Istio enables HPE to manage Istio service meshes and configurations, automate the deployment of Istio components, and monitor and visualize Istio metrics and traces. This integration enables HPE to simplify the management of their Istio service meshes, ensure their security and compliance, and gain insights into their behavior for better decision-making.&lt;/p&gt;&lt;p&gt;Overall, HPE&amp;#x27;s adoption of Meshery, along with its integration with SPIRE and Istio, has enabled the company to streamline their service mesh management, ensure the security and compliance of their Kubernetes environment, and gain valuable insights into the behavior of their service meshes for improved performance and reliability.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Meshery also implements the Service Mesh Performance (SMP) specification&lt;/b&gt;&lt;/p&gt;&lt;p&gt;SMP is a community-driven effort that provides a standard for measuring and comparing the performance of different service meshes. It is designed to help users select the best service mesh for their needs by providing a common framework for benchmarking.&lt;/p&gt;&lt;div class=&quot;Inline-quotes__QuotesWrapper-sc-hv31e3-0 cRZWJU&quot;&gt;&lt;div class=&quot;quote-box&quot;&gt;&lt;h4&gt;❝ The Layer5 team has been amazing. Our project wouldn’t have been successful with out Meshery. ❞&lt;/h4&gt;&lt;hr/&gt;&lt;img src=&quot;/static/yogi-d00ca1cc48ab74938a23d4359ef3fb01.webp&quot;/&gt;&lt;div class=&quot;quote-source&quot;&gt;&lt;h5&gt;Yogi Porla&lt;/h5&gt;&lt;p&gt;Engineering Manager, HPE&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt;Meshery implements SMP by providing a simple and easy-to-use interface for running performance tests against different service meshes. Users can select the service mesh they want to test, configure the test parameters (such as the number of requests per second and the number of concurrent clients), and run the test. Meshery will then generate a report that shows the performance metrics for each service mesh, such as latency, throughput, and error rates.&lt;/p&gt;&lt;p&gt;By implementing SMP, Meshery provides a valuable tool for developers and operators who are evaluating different service meshes. Instead of having to create their own benchmarks, they can use SMP to get an objective and standardized view of each service mesh&amp;#x27;s performance characteristics. This can save a significant amount of time and effort, and help users make more informed decisions when choosing a service mesh.&lt;/p&gt;&lt;p&gt;Overall, HPE&amp;#x27;s use of Meshery and the Docker Extension for Meshery demonstrates the power of cloud native technologies and the importance of open source collaboration. By leveraging these tools, HPE has been able to streamline its development and deployment processes, improve performance and security, and stay at the forefront of the cloud native movement.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Changing Meshery Release Channels]]></title><description><![CDATA[Meshery is constantly evolving and improving, with new features and bug fixes being added regularly. To stay up to date with the latest Meshery features and updates, you can switch between different release channels.]]></description><link>https://layer5.io/blog/meshery/changing-meshery-release-channels</link><guid isPermaLink="false">https://layer5.io/blog/meshery/changing-meshery-release-channels</guid><dc:creator><![CDATA[Karan Thakur]]></dc:creator><pubDate>Fri, 16 Jun 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/60fe9ee92d711b8b6d591e00535d18ef/change-meshery-release-channels.png" length="0" type="image/png"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Meshery is constantly evolving and improving, with new features and bug fixes being added regularly. To stay up to date with the latest Meshery features and updates, you can switch between different release channels.&lt;/p&gt;&lt;p&gt;Artifacts of the builds for Meshery and its components are published under two different release channels, so that improved controls may be provided to both  Meshery users and Meshery developers. The two release channels are edge and stable release channels. Relative to stable releases, edge releases occur much more frequently. Edge releases are made with each merge to master, unless that merge to master is for a stable release. Stable releases are made with each merge to master when a GitHub release tag is also present in the workflow.&lt;/p&gt;&lt;h2&gt; How release channels offer subscription &lt;/h2&gt;&lt;p&gt;Release Channels offers a subscription where user can subscribe to a specific  release channel and get notified when a new release is available. This is  useful for users who want to stay up to date with the latest Meshery features, while also also providing flexibility for users who want to stay on a specific version of Meshery. However, this approach can be risky because some updates may introduce bugs or compatibility issues that could break your existing installation. Depending upon your risk aversion and the nature of your deployment environment, having a subscription means that you will automatically receive these updates that you might not be ready incorporate. On the other hand, release channels also offer the ability to pin to a specific release which is a  good thing as it allows users to maintain stability and predictability of their environment by preventing unexpected changes from being introduced into their system. However, doing so cancels out any future subscription-based benefits such as receiving security patches or bug fixes that were added after that version was released.&lt;p&gt;Therefore, it&amp;#x27;s important for you to weigh the pros and cons of each option before making decisions on how you want to manage your Meshery deployment. It&amp;#x27;s recommended you and your organizations have a well-defined upgrade strategy based on testing and validation procedures prior to applying new releases in production environments whether via subscriptions or manual upgrades to ensure that system availability is maintained and risks are minimized.&lt;/p&gt;&lt;/p&gt;&lt;p&gt;To subscribe to a specific release channel or version using mesheryctl you can use&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system channel &lt;/span&gt;&lt;span class=&quot;token builtin class-name&quot; style=&quot;color:rgb(255, 203, 139)&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;stable&lt;/span&gt;&lt;span class=&quot;token operator&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;stable-version&lt;/span&gt;&lt;span class=&quot;token operator&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;token operator&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;edge-version&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;This command will update your local Meshery configuration to use the selected channel for future updates. To set the channel to a specific version, replace Version with the desired version number. Example: &lt;code class=&quot;language-bash&quot;&gt;mesheryctl system channel set stable&lt;/code&gt; or &lt;code class=&quot;language-bash&quot;&gt;mesheryctl system channel set stable-v0.5.56&lt;/code&gt;&lt;/p&gt;&lt;h2&gt; Switching between Release Channels&lt;/h2&gt;&lt;p&gt;There are two ways to switch between Meshery release channels: using mesheryctl or by editing your meshconfig file. In this blog post, we&amp;#x27;ll cover both methods.&lt;/p&gt;&lt;h3&gt;What is Meshconfig?&lt;/h3&gt;&lt;p&gt;Meshconfig is a configuration file that is used to configure Meshery. It is typically located in the &lt;code&gt;~/.meshery/config.yaml&lt;/code&gt; directory. It contains information about the current release channel, the version of Meshery that is installed, and other configuration options that are specific to your Meshery installation. Meshconfig is automatically generated when you run Meshery for the first time. It is also automatically updated when you update Meshery&lt;/p&gt;&lt;ol&gt;&lt;h3&gt;Switching between Meshery release channels using meshconfig file.&lt;/h3&gt;&lt;p&gt;Open your terminal and confirm that you have mesheryctl installed by running  &lt;code&gt;mesheryctl version&lt;/code&gt;. If you don&amp;#x27;t have mesheryctl installed, you can install it by following the instructions in the  &lt;a href=&quot;https://docs.meshery.io/installation/mesheryctl&quot;&gt;Meshery documentation&lt;/a&gt;.&lt;/p&gt;&lt;li&gt;Create new Meshery config.yaml file &lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-language=bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context create [context-name]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;Example: &lt;br/&gt; &lt;code class=&quot;language-bash&quot;&gt;mesheryctl system context create new-context --components meshery-istio meshery-osm meshery-linkerd --platform docker --url http://localhost:9081 --set --yes &lt;/code&gt;&lt;li&gt; To view the newly created meshery context use &lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context view &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;context-name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;After making these changes, you can switch between different context by using &lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context switch&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Switching between Meshery release channels using mesheryctl.&lt;/h3&gt;&lt;p&gt;mesheryctl is a command-line tool for managing Meshery. You can use it to switch between different release channels. Here&amp;#x27;s how:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Run the following command to see the current configuration for Meshery:&lt;/li&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system context view&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;img src=&quot;/static/meshery-version-5dbe26bc558062b5cc58ff22a8e88b49.png&quot; class=&quot;image-center&quot; style=&quot;width:50%&quot;/&gt;&lt;p&gt;This will show you the currently channels ,&lt;b&gt;stable&lt;/b&gt; or &lt;b&gt;edge&lt;/b&gt;, along with the version number and other information.&lt;/p&gt;&lt;li&gt;Run the following command to switch to a different release channel:&lt;/li&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system channel switch&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;This command will update your meshconfig file to switch release channel and version of context in focus. To switch the channel to a specific version, replace &lt;b&gt;Version&lt;/b&gt; with the desired version number.&lt;li&gt; To confirm that the channel has been changed, run the following command again: &lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-bash&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mesheryctl system channel view&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Conclusion &lt;/h2&gt;&lt;p&gt;Switching between Meshery release channels is a simple and straightforward process. You can do it using mesheryctl or by switching between your meshconfig file. Whether you want stable updates or bleeding-edge features, Meshery has a release channel that suits your needs. Just remember to carefully consider your use case and needs before making any changes to ensure that you have the best Meshery experience.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Configuring Highly Available Docker Swarm]]></title><link>https://layer5.io/resources/docker/configuring-highly-available-docker-swarm</link><guid isPermaLink="false">https://layer5.io/resources/docker/configuring-highly-available-docker-swarm</guid><pubDate>Thu, 18 May 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/5b72df1802df0608ac6ee6e6bff70c9d/docker-swarm.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt;Docker Swarm is a &lt;a href=&quot;/articles/kubernetes/management-of-kubernetes&quot;&gt;container orchestration&lt;/a&gt; tool that makes it easy to manage and scale your existing Docker infrastructure. It consists of a pool of Docker hosts that run in Swarm mode with some nodes acting as managers, workers, or both. Using Docker Swarm mode to manage your Docker containers brings the following benefits:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;It allows you to incrementally apply updates with zero downtime.&lt;/li&gt;&lt;li&gt;It increases application resilience to outages by reconciling any differences between the actual state and your expressed desired state.&lt;/li&gt;&lt;li&gt;It eases the process of scaling your applications since you only need to define the desired number of replicas in the cluster.&lt;/li&gt;&lt;li&gt;It is built into the &lt;code&gt;docker&lt;/code&gt; CLI, so you don&amp;#x27;t need additional software to get up and running.&lt;/li&gt;&lt;li&gt;It enables multi-host networking such that containers deployed on different nodes can communicate with each other easily.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In this tutorial, you will learn key concepts in Docker Swarm and set up a highly available Swarm cluster that is resilient to failures. You will also learn some best practices and recommendations to ensure that your Swarm setup is fault tolerant.&lt;/p&gt;&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;&lt;p&gt;Before proceeding with this tutorial, ensure that you have access to five Ubuntu 22.04 servers. This is necessary to demonstrate a highly available set up, although it is also possible to run Docker Swarm on a single machine. You also need to configure each server with a user that has administrative privileges.&lt;/p&gt;&lt;p&gt;The following ports must also be available on each server for communication purposes between the nodes. On Ubuntu 22.04, they are open by default:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TCP port 2377 for cluster management communications,&lt;/li&gt;&lt;li&gt;TCP and UDP port 7946 for communication among nodes,&lt;/li&gt;&lt;li&gt;TCP and UDP port 4789 for overlay network traffic.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;explaining-docker-swarm-terminology&quot;&gt;Explaining Docker Swarm terminology&lt;/h2&gt;&lt;p&gt;Before proceeding with this tutorial, let&amp;#x27;s examine some terms and definitions in Docker Swarm so that you have enough understanding of what each one means when they are used in this article and in other Docker Swarm resources.&lt;/p&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Node&lt;/strong&gt;: refers to an instance of the Docker engine in the Swarm cluster.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Manager nodes&lt;/strong&gt;: they are tasked with handling orchestration and cluster management functions, and dispatching incoming tasks to worker nodes. They can also act as worker nodes unless placed in Drain mode (recommended).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Leader&lt;/strong&gt;: this is a specific manager node that is elected to perform orchestration tasks and management/maintenance operations by all the manager nodes in the cluster using the &lt;a rel=&quot;&quot; target=&quot;_blank&quot; class=&quot;whitespace-nowrap&quot; href=&quot;https://raft.github.io/&quot;&gt;Raft Consensus Algorithm&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Worker nodes&lt;/strong&gt;: are Docker instances whose sole purpose is to receive and execute Swarm tasks from manager nodes.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Swarm task&lt;/strong&gt;: refers to a Docker container and the commands that run inside the container. Once a task is assigned to a node, it can run or fail but it cannot be transferred to a different node.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Swarm service&lt;/strong&gt;: this is the mechanism for defining tasks that should be executed on a node. It involves specifying the container image and commands that should run inside the container.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Drain&lt;/strong&gt;: means that new tasks are no longer assigned to a node, and existing tasks are reassigned to other available nodes.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;docker-swarm-requirements-for-high-availability&quot;&gt;Docker Swarm requirements for high availability&lt;/h2&gt;&lt;p&gt;A highly available Docker Swarm setup ensures that if a node fails, services on the failed node are re-provisioned and assigned to other available nodes in the cluster. A Docker Swarm setup that consists of one or two manager nodes is not considered highly available because any incident will cause operations on the cluster to be interrupted. Therefore the minimum number of manager nodes in a highly available Swarm cluster should be three.&lt;/p&gt;&lt;p&gt;The table below shows the number of failures a Swarm cluster can tolerate depending on the number of manager nodes in the cluster:&lt;/p&gt;&lt;div&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Manager Nodes&lt;/th&gt;&lt;th&gt;Failures tolerated&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt;As you can see, having an even number of manager nodes does not help with failure tolerance, so you should always maintain an odd number of manager nodes. Fault tolerance improves as you add more manager nodes, but Docker recommends no more than seven managers so that performance is not negatively impacted since each node must acknowledge proposals to update the state of the cluster.&lt;/p&gt;&lt;p&gt;You should also distribute your manager nodes in separate locations so they are not affected by the same outage. If they run on the same server, a hardware problem could cause them all to go down. The high availability Swarm cluster that you will be set up in this tutorial will therefore exhibit the following characteristics:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;5 total nodes (2 workers and 3 managers) with each one running on a separate server.&lt;/li&gt;&lt;li&gt;2 worker nodes (&lt;code&gt;worker-1&lt;/code&gt; and &lt;code&gt;worker-2&lt;/code&gt;).&lt;/li&gt;&lt;li&gt;3 manager nodes (&lt;code&gt;manager-1&lt;/code&gt;, &lt;code&gt;manager-2&lt;/code&gt;, and &lt;code&gt;manager-3&lt;/code&gt;).&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;playground-CTA__DockerExtensionCTAWrapper-sc-1hwzasi-0 kkBDbd&quot;&gt;&lt;div class=&quot;Container__ContainerWrapper-sc-1i64mot-0 fjHmlh&quot;&gt;&lt;div class=&quot;playground-callout&quot;&gt;&lt;div class=&quot;dots-icon&quot;&gt;&lt;/div&gt;&lt;div class=&quot;card-left&quot;&gt;&lt;img class=&quot;meshery-title&quot; src=&quot;data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDU0IiBoZWlnaHQ9IjU2IiB2aWV3Qm94PSIwIDAgNDU0IDU2IiBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgo8ZyBjbGlwLXBhdGg9InVybCgjY2xpcDBfMTM2NzRfMTk0NjUpIj4KPHBhdGggZD0iTTY5LjkwMTUgNTZINTguMDUyMVYxNS4xNDc4QzU4LjA1NzIgMTQuNzEzIDU3Ljk2NzggMTQuMjgyMyA1Ny43OTAzIDEzLjg4NTVDNTcuNjI5NyAxMy40OTEzIDU3LjM5MDIgMTMuMTM0MiA1Ny4wODY1IDEyLjgzNjNDNTYuNzg2MyAxMi41MzU1IDU2LjQzMDUgMTIuMjk2MSA1Ni4wMzkgMTIuMTMxNEM1NS42NDI5IDExLjk1MzUgNTUuMjEyOSAxMS44NjQgNTQuNzc4OCAxMS44NjkxSDBWMC4wMDAzMTUwNjRINTQuNzc4OEM1Ni43ODg0IC0wLjAxMjk4MDUgNTguNzc4NiAwLjM5NDY2IDYwLjYyMTcgMS4xOTcwNUM2Mi40NTI1IDEuOTY1NjIgNjQuMTE5MiAzLjA3ODU5IDY1LjUzMTYgNC40NzU3MkM2Ni45MyA1Ljg4NzYgNjguMDQxNiA3LjU1Nzc5IDY4LjgwNDkgOS4zOTM3MkM2OS42MDYgMTEuMjM5OCA3MC4wMTMgMTMuMjMzMiA2OS45OTk3IDE1LjI0NjFMNjkuOTAxNSA1NlpNMTEuODQ5NCA1NkgwVjExLjg2OTFMMTEuODQ5NCA4LjU5MDQ0VjU2Wk00MC44MzQ1IDU2SDI4Ljk4NTFWMTguMDk4Nkg0MC45MTYzTDQwLjgzNDUgNTZaIiBmaWxsPSIjRkJGQkZCIi8+CjxwYXRoIGQ9Ik03NiA4LjgyMjI0VjExLjJWMjIuNFYzNi4wNTk3VjU2SDEzMFY0NC44SDg3LjM5MDRWMzYuMDU5N1YzMy42SDEyMC4xMjdWMjIuNEg4Ny4zOTA0VjExLjJIMTMwVjBINzZWOC44MjIyNFoiIGZpbGw9IiNGQkZCRkIiLz4KPHBhdGggZD0iTTIwMi45NTEgNDEuMzU2NUMyMDIuOTY4IDQzLjMwNyAyMDIuNTc4IDQ1LjIzOTcgMjAxLjgwNyA0Ny4wMzAyQzIwMS4wNyA0OC43ODQgMTk5Ljk5MyA1MC4zNzI4IDE5OC42MzcgNTEuNzAzNkMxOTcuMjkxIDUzLjAyMDQgMTk1LjcxOSA1NC4wODE2IDE5My45OTYgNTQuODM1N0MxOTIuMTk0IDU1LjYxMDYgMTkwLjI1MyA1Ni4wMDY5IDE4OC4yOTMgNTUuOTk5OUgxMzZWNDQuMTkzM0gxODguMjkzQzE4OC42NjUgNDQuMTk3NyAxODkuMDM1IDQ0LjEyNzMgMTg5LjM4IDQzLjk4NjNDMTg5LjcyNSA0My44NDUzIDE5MC4wMzggNDMuNjM2NSAxOTAuMzAxIDQzLjM3MjJDMTkwLjU2NSA0My4xMDc5IDE5MC43NzMgNDIuNzkzNCAxOTAuOTEzIDQyLjQ0NzNDMTkxLjA1NCA0Mi4xMDExIDE5MS4xMjQgNDEuNzMwMiAxOTEuMTIgNDEuMzU2NVYzNi43OTc4QzE5MS4xMjIgMzYuNDI0NiAxOTEuMDUgMzYuMDU0OCAxOTAuOTA5IDM1LjcwOTZDMTkwLjc2OCAzNS4zNjQ0IDE5MC41NiAzNS4wNTA4IDE5MC4yOTcgMzQuNzg3QzE5MC4wMzQgMzQuNTIzMSAxODkuNzIxIDM0LjMxNDIgMTg5LjM3NyAzNC4xNzI0QzE4OS4wMzMgMzQuMDMwNyAxODguNjY1IDMzLjk1ODggMTg4LjI5MyAzMy45NjA5SDE1MC43MDdDMTQ4Ljc2MyAzMy45NzgxIDE0Ni44MzggMzMuNTg3MSAxNDUuMDUzIDMyLjgxMzFDMTQxLjUyMyAzMS4yOTkxIDEzOC43MDkgMjguNDgwOSAxMzcuMTkzIDI0Ljk0MkMxMzYuNDIzIDIzLjE0NTMgMTM2LjAzMyAyMS4yMDc2IDEzNi4wNDkgMTkuMjUxOVYxNC43MDk2QzEzNi4wMzYgMTIuNzQzNiAxMzYuNDI2IDEwLjc5NTggMTM3LjE5MyA4Ljk4NjY3QzEzNy45NDYgNy4yNDY4IDEzOS4wMjIgNS42NjY0MyAxNDAuMzYzIDQuMzI5NjNDMTQxLjcwNiAyLjk3NDQ3IDE0My4yOTkgMS44OTQwNCAxNDUuMDUzIDEuMTQ4NEMxNDYuODM4IDAuMzc0MzQ1IDE0OC43NjMgLTAuMDE2NjQzNCAxNTAuNzA3IDAuMDAwNTQyOTY2SDIwM1YxMS44Mzk5SDE1MC43MDdDMTUwLjMzNCAxMS44Mjg1IDE0OS45NjIgMTEuODk1NSAxNDkuNjE2IDEyLjAzNjdDMTQ5LjI3IDEyLjE3NzkgMTQ4Ljk1NyAxMi4zOTAxIDE0OC42OTcgMTIuNjU5OEMxNDguNDMxIDEyLjkyMjEgMTQ4LjIyMSAxMy4yMzY0IDE0OC4wOCAxMy41ODMzQzE0Ny45NCAxMy45MzAzIDE0Ny44NzIgMTQuMzAyNCAxNDcuODggMTQuNjc2OFYxOS4yMTkxQzE0Ny44NzIgMTkuNTkzNSAxNDcuOTQgMTkuOTY1NiAxNDguMDggMjAuMzEyNUMxNDguMjIxIDIwLjY1OTUgMTQ4LjQzMSAyMC45NzM4IDE0OC42OTcgMjEuMjM2QzE0OC45NTcgMjEuNTA1NyAxNDkuMjcgMjEuNzE4IDE0OS42MTYgMjEuODU5MkMxNDkuOTYyIDIyLjAwMDQgMTUwLjMzNCAyMi4wNjc0IDE1MC43MDcgMjIuMDU1OUgxODguMjkzQzE5MC4yNTMgMjIuMDQ5IDE5Mi4xOTQgMjIuNDQ1MiAxOTMuOTk2IDIzLjIyMDJDMTk1LjcyNyAyMy45ODAxIDE5Ny4zMDIgMjUuMDU5MiAxOTguNjM3IDI2LjQwMTRDMTk5Ljk3OCAyNy43MzgyIDIwMS4wNTQgMjkuMzE4NiAyMDEuODA3IDMxLjA1ODVDMjAyLjU3NCAzMi44NjIgMjAyLjk2MyAzNC44MDQzIDIwMi45NTEgMzYuNzY1VjQxLjM1NjVaIiBmaWxsPSIjRkJGQkZCIi8+CjxwYXRoIGQ9Ik0yNzEgNTZIMjYwLjQ5NVYzMy45NjA3SDIxOS41MDVWNTZIMjA5VjIyLjA4ODRIMjYwLjQ5NVYwSDI3MVY1NlpNMjE5LjUwNSAxNi43NzU0SDIwOVYwSDIxOS41MDVWMTYuNzc1NFoiIGZpbGw9IiNGQkZCRkIiLz4KPHBhdGggZD0iTTI3NyA4LjgyMjI0VjExLjJWMjIuNFYzNi4wNTk3VjU2SDMzMFY0NC44SDI4OC4xODNWMzYuMDU5N1YzMy42SDMyMC4zMDdWMjIuNEgyODguMTgzVjExLjJIMzMwVjBIMjc3VjguODIyMjRaIiBmaWxsPSIjRkJGQkZCIi8+CjxwYXRoIGQ9Ik0zNDYuOTU0IDEwLjY3NTJIMzc1LjYyNlYyMi4zMThIMzUyLjUzOFYzMi45OTMySDM1Ny44MjdMMzc4LjExNSA1NS45NTA4SDM5MkwzNzEuNzEyIDMyLjk5MzJIMzc5LjYzN0MzODAuNzc3IDMyLjk5MzIgMzgxLjkwNiAzMi43Njg0IDM4Mi45NTggMzIuMzMxN0MzODQuMDExIDMxLjg5NDkgMzg0Ljk2OCAzMS4yNTQ3IDM4NS43NzQgMzAuNDQ3N0MzODYuNTggMjkuNjQwNiAzODcuMjE5IDI4LjY4MjYgMzg3LjY1NSAyNy42MjgxQzM4OC4wOTEgMjYuNTczNyAzODguMzE2IDI1LjQ0MzUgMzg4LjMxNiAyNC4zMDIyVjguNjkxMDdDMzg4LjMxNiA3LjU0OTc0IDM4OC4wOTEgNi40MTk1OCAzODcuNjU1IDUuMzY1MTNDMzg3LjIxOSA0LjMxMDY4IDM4Ni41OCAzLjM1MjU4IDM4NS43NzQgMi41NDU1NEMzODQuOTY4IDEuNzM4NSAzODQuMDExIDEuMDk4MzIgMzgyLjk1OCAwLjY2MTU0OUMzODEuOTA2IDAuMjI0NzgyIDM4MC43NzcgMCAzNzkuNjM3IDBIMzM2VjU2SDM0Ny4xODRMMzQ2Ljk1NCAxMC42NzUyWiIgZmlsbD0iI0ZCRkJGQiIvPgo8cGF0aCBkPSJNNDI2LjAwOCAxOS41OTU5TDQxMi4wMDQgMEgzOThMNDIwLjQgMzMuNlY1Nkg0MzEuNlYzMy42TDQ1NCAwSDQ0MC4xNzZMNDI2LjAwOCAxOS41OTU5WiIgZmlsbD0iI0ZCRkJGQiIvPgo8L2c+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzNjc0XzE5NDY1Ij4KPHJlY3Qgd2lkdGg9IjQ1NCIgaGVpZ2h0PSI1NiIgZmlsbD0id2hpdGUiLz4KPC9jbGlwUGF0aD4KPC9kZWZzPgo8L3N2Zz4K&quot; alt=&quot;Meshery Title&quot; loading=&quot;lazy&quot;/&gt;&lt;div class=&quot;playground&quot;&gt;Playground&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;card-right&quot;&gt;&lt;div&gt;&lt;h4&gt;Connect to live clusters&lt;br/&gt;Discover, validate, and visualize&lt;br/&gt;Kubernetes infrastructure with ease.&lt;/h4&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;a href=&quot;https://play.meshery.io/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 kpjYoD appion__btn&quot;&gt;Try Playground now! &lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;meshery-icon&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;docker-extension-CTA__DockerExtensionCTAWrapper-sc-1ahss27-0 jfeaRg&quot;&gt;&lt;div class=&quot;Container__ContainerWrapper-sc-1i64mot-0 fjHmlh&quot;&gt;&lt;div class=&quot;docker-callout&quot;&gt;&lt;img src=&quot;/static/Docker_animated.d3f14ac8.svg&quot; alt=&quot;Docker and Meshery&quot; loading=&quot;lazy&quot;/&gt;&lt;div class=&quot;card-right&quot;&gt;&lt;div&gt;&lt;h2&gt;Docker Extension for Meshery&lt;br/&gt; is now available!&lt;/h2&gt;&lt;/div&gt;&lt;p&gt;Managing cloud native infrastructure has never been easier.&lt;/p&gt;&lt;a href=&quot;/docker-extension-meshery&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 kpjYoD appion__btn&quot;&gt;Use the Meshery Docker Extension &lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2 id=&quot;step-1-installing-docker&quot;&gt;Step 1 — Installing Docker&lt;/h2&gt;&lt;p&gt;In this step, you will install Docker on all five Ubuntu servers. Therefore, execute all the commands below (and in step 2) on all five servers. If your host offers a snapshot feature, you may be able to run the commands on a single server and use that server as a base for the other four instances.&lt;/p&gt;&lt;p&gt;Let&amp;#x27;s start by installing the latest version of the Docker Engine (20.10.18 at the time of writing). Go ahead and update the package information list from all configured sources on your system:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo apt update&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Afterward, install the following packages to allow &lt;code&gt;apt&lt;/code&gt; to use packages over HTTPS:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo apt install apt-transport-https ca-certificates curl software-properties-common&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Next, add the GPG key for the official Docker repository to the server:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Once the GPG key is added, include the official Docker repository in the server&amp;#x27;s apt sources list:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;echo &amp;quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&amp;quot; | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Finally, update apt once again and install the Docker Engine:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo apt update&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo apt install docker-ce&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Once the relevant packages are installed, you can check the status of the &lt;code&gt;docker&lt;/code&gt; service using the command below:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo systemctl status docker&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If everything goes well, you should observe that the container engine is active and running on your server.&lt;/p&gt;&lt;h2 id=&quot;step-2-executing-the-docker-command-without-sudo&quot;&gt;Step 2 — Executing the Docker command without sudo&lt;/h2&gt;&lt;p&gt;By default, the &lt;code&gt;docker&lt;/code&gt; command can only be executed by the root user or any user in the &lt;code&gt;docker&lt;/code&gt; group (auto created on installation). If you execute a &lt;code&gt;docker&lt;/code&gt; command without prefixing it with &lt;code&gt;sudo&lt;/code&gt; or running it through a user that belongs to the &lt;code&gt;docker&lt;/code&gt; group, you will get a permission error that looks like this:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get &amp;quot;http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/json&amp;quot;: dial unix /var/run/docker.sock: connect: permission denied&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;As mentioned earlier, using &lt;code&gt;sudo&lt;/code&gt; with &lt;code&gt;docker&lt;/code&gt; is a security risk, so the solution to the above error is to add the relevant user to the &lt;code&gt;docker&lt;/code&gt; group. This can be achieved through the command below:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;sudo usermod -aG docker $USER&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Next, run the following command and enter the user&amp;#x27;s password when prompted for the changes to take effect:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;su - $USER&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;You should now be able to run &lt;code&gt;docker&lt;/code&gt; commands without prefixing them with &lt;code&gt;sudo&lt;/code&gt;. For example, when you run the command &lt;code&gt;docker ps&lt;/code&gt;, you should observe the output.&lt;/p&gt;&lt;p&gt;Before proceeding to the next step, ensure that all the commands in step 1 and step 2 have been executed on all five servers.&lt;/p&gt;&lt;h2&gt;Step 3 — Initializing the Swarm Cluster&lt;/h2&gt;&lt;p&gt;At this point, each of your five Docker instances are acting as separate hosts and not as part of a Swarm cluster. Therefore, in this step, we will initialize the Swarm cluster on the &lt;code&gt;manager-1&lt;/code&gt; server and add the hosts to the cluster accordingly.&lt;/p&gt;&lt;p&gt;Start by logging into one of the Ubuntu servers (&lt;code&gt;manager-1&lt;/code&gt;) and retrieve the private IP address of the machine using the following command:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;hostname -I | awk &amp;#x27;{print $1}&amp;#x27;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Copy the IP address to your clipboard and replace the &lt;code&gt;&amp;lt;manager_1_server_ip&amp;gt;&lt;/code&gt; placeholder in the command below to initialize Swarm mode:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker swarm init --advertise-addr &amp;lt;manager_1_server_ip&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If the command is successful, you will see output indicating that the Swarm has been initialized and that the current node is now a manager. It will also provide a command to join worker nodes to the cluster. Copy the command for later use.&lt;/p&gt;&lt;p&gt;Next, SSH into each of the other four Ubuntu servers (manager-2, manager-3, worker-1, and worker-2) and run the command you copied earlier to join them to the Swarm cluster. The command should look like this:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker swarm join --token &amp;lt;token&amp;gt; &amp;lt;manager_1_server_ip&amp;gt;:&amp;lt;port&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;After running the command on each server, you should see output indicating that the node has joined the Swarm as either a manager or a worker. To verify the status of the Swarm cluster, you can run the command &lt;code&gt;docker node ls&lt;/code&gt; on the manager node:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker node ls&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;You should see a list of all the nodes in the Swarm cluster, including their IDs, hostname, status, availability, and whether they are a manager or a worker.&lt;/p&gt;&lt;h2&gt;Step 4 — Deploying the Application Stack&lt;/h2&gt;&lt;p&gt;Now that you have a functioning Docker Swarm cluster, you can deploy your application stack. In this tutorial, we will use a simple example of a web application stack consisting of a front-end service and a back-end service.&lt;/p&gt;&lt;p&gt;Start by creating a new directory for your application stack on the manager node:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;mkdir app-stack cd app-stack&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Next, create a file called &lt;code&gt;docker-compose.yml&lt;/code&gt; in the &lt;code&gt;app-stack&lt;/code&gt; directory and open it in a text editor:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;nano docker-compose.yml&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;Copy and paste the following YAML code into the &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;version: &amp;#x27;3.8&amp;#x27; services: frontend: image: nginx:latest ports: - 80:80 deploy: replicas: 2 restart_policy: condition: on-failure backend: image: httpd:latest ports: - 8080:80 deploy: replicas: 2 restart_policy: condition: on-failure&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;This Docker Compose file defines two services: &lt;code&gt;frontend&lt;/code&gt; and &lt;code&gt;backend&lt;/code&gt;. The &lt;code&gt;frontend&lt;/code&gt; service uses the &lt;code&gt;nginx:latest&lt;/code&gt; image and maps port 80 of the host to port 80 of the container. It is configured to have 2 replicas and to restart on failure. The &lt;code&gt;backend&lt;/code&gt; service uses the &lt;code&gt;httpd:latest&lt;/code&gt; image and maps port 8080 of the host to port 80 of the container. It is also configured to have 2 replicas and to restart on failure.&lt;/p&gt;&lt;p&gt;Save and close the &lt;code&gt;docker-compose.yml&lt;/code&gt; file.&lt;/p&gt;&lt;p&gt;To deploy the application stack, run the following command:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker stack deploy -c docker-compose.yml app-stack&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If the command is successful, you should see output indicating that the services are being deployed. You can check the status of the services by running the command &lt;code&gt;docker service ls&lt;/code&gt;:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;docker service ls&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;You should see a list of the services in the stack, including their names, mode, replicas, and ports.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;In this tutorial, you learned how to set up a highly available Docker Swarm cluster and deploy a simple application stack. This setup provides fault tolerance and load balancing for your applications, allowing you to scale them easily as your needs grow.&lt;/p&gt;&lt;p&gt;Next steps:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Explore more Docker Swarm features, such as service updates and rolling updates.&lt;/li&gt;&lt;li&gt;Deploy your own application stack using Docker Compose.&lt;/li&gt;&lt;li&gt;Learn about Docker networking and how to create overlay networks.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Kubernetes NodePorts - Static and Dynamic Assignments]]></title><description><![CDATA[Avoiding Port Collisions with Kubernetes NodePorts Static and Dynamic Assignments]]></description><link>https://layer5.io/blog/kubernetes/kubernetes-nodeports-static-and-dynamic-assignments</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/kubernetes-nodeports-static-and-dynamic-assignments</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Fri, 12 May 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/7ff62eaeba27512aa31c04535a060e72/k8s-nodeports.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Kubernetes provides a Service to offer a unified traffic endpoint for the Pods. While it offers a VIP to the clients for access and Kubernetes ensures traffic balancing for the accessing back-end Pods, it has a limitation of routing traffic from outside the cluster. The Kubernetes Service setting of &amp;quot;NodePort&amp;quot; was created to overcome this issue. &lt;/p&gt;&lt;p&gt;By setting up a mapping to a specific port of all nodes in the cluster, a NodePort Service redirects traffic from the outside to the inside of the cluster. When a NodePort Service is created, Kubernetes control plane allocates its corresponding ports in two ways. The first is dynamic, where Kubernetes control plane automatically assigns an unused port at the creation time. The second is static, which assigns a port within the nodeport port range configuration. It is crucial to assign a unique nodePort across the entire cluster while manually assigning nodePort, or it will result in an error if a service of type NodePort already uses that port. &lt;/p&gt;&lt;p&gt;Sometimes, there is a need to run a NodePort Service on well-known ports so that other components and users inside or outside the cluster can use them. In such cases, users need to reserve the required ports before using them. Kubernetes 1.27 introduced a new feature gate &amp;quot;ServiceNodePortStaticSubrange&amp;quot; that allows users to use a different port allocation strategy for type NodePort Services. Enabling this feature gate will divide the port range for NodePort Services based on a formula that uses nodeport size and determines the size of the static port range.&lt;/p&gt;&lt;p&gt;Here are a few examples of different port ranges and their band offset values:&lt;/p&gt;&lt;div class=&quot;table-3&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Range properties&lt;/th&gt;&lt;th&gt;Values&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;service-node-port-range&lt;/td&gt;&lt;td&gt;30000-32767&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Band Offset&lt;/td&gt;&lt;td&gt;86&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Static band start&lt;/td&gt;&lt;td&gt;30000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Static band end&lt;/td&gt;&lt;td&gt;30085&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dynamic band start&lt;/td&gt;&lt;td&gt;30086&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dynamic band end&lt;/td&gt;&lt;td&gt;32767&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;br/&gt;&lt;div class=&quot;table-3&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Range properties&lt;/th&gt;&lt;th&gt;Values&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;service-node-port-range&lt;/td&gt;&lt;td&gt;30000-30015&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Band Offset&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Static band start&lt;/td&gt;&lt;td&gt;30000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Static band end&lt;/td&gt;&lt;td&gt;30015&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dynamic band start&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dynamic band end&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt;NodePort Services can be useful in many scenarios. For example, consider a user that needs to expose a Minio object storage service on Kubernetes to clients running outside the Kubernetes cluster. The agreed port is 30009, and the user needs to create a Service as follows:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-undefined&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;apiVersion: v1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;kind: Service&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;metadata:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  name: minio&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;spec:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  ports:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  - name: api&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    nodePort: 30009&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    port: 9000&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    protocol: TCP&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    targetPort: 9000&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  selector:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    app: minio&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  type: NodePort&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;p&gt;If the port required for the Minio Service is not reserved and another NodePort (or possibly LoadBalancer) Service is created and dynamically allocated before or concurrently with the Minio Service, the TCP port 30009 might be allocated to that other Service. In this case, creation of the Minio Service will fail due to a node port collision. &lt;/p&gt;&lt;p&gt;In conclusion, using the NodePort Service will help Kubernetes users by allowing traffic to be routed from outside to inside the cluster, providing a unified traffic endpoint for the Pods. By enabling the ServiceNodePortStaticSubrange feature gate, users can adopt a different port allocation strategy, reducing the risk of collisions while using a different range of ports.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[What are Kubernetes Validating Admission Controllers?]]></title><description><![CDATA[Kubernetes Validating Admission Controllers and Policies use the Common Expression Language (CEL) to offer a declarative, in-process alternative to Validating Admission Webhooks.]]></description><link>https://layer5.io/blog/kubernetes/what-are-kubernetes-validating-admission-controllers</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/what-are-kubernetes-validating-admission-controllers</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Fri, 03 Feb 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/0cda4651daf491c6b40dd404799ca32c/kubernetes-new.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;Kubernetes is an open-source container orchestration system for automating the deployment, scaling, and management of containerized applications. As part of its functionality, Kubernetes offers a feature called &amp;quot;Admission Controllers&amp;quot; that allow administrators to enforce certain policies on resources being created in the cluster.&lt;/p&gt;&lt;p&gt;In this blog post, we will be discussing a new feature in Kubernetes called &amp;quot;Validating Admission Policies&amp;quot; which is currently in alpha stage. This feature allows administrators to define custom validation rules for resources being created in the cluster and enforce those rules using admission controllers.&lt;/p&gt;&lt;h2&gt;What are Admission Controllers?&lt;/h2&gt;&lt;p&gt;Admission controllers are pluggable components in the Kubernetes API server that intercept requests to create, update, or delete resources in the cluster. They allow administrators to enforce certain policies on these requests before they are persisted in the etcd database and acted upon by the Kubernetes control plane.&lt;/p&gt;&lt;p&gt;There are various types of admission controllers available in Kubernetes, such as:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;NamespaceLifecycle&lt;/strong&gt;: This admission controller enforces policies related to namespace creation and deletion.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;LimitRanger&lt;/strong&gt;: This admission controller enforces resource limits on pods, such as CPU and memory limits.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;PodSecurityPolicy&lt;/strong&gt;: This admission controller enforces security policies on pods, such as privileged mode, host networking, and volumes.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Validating Admission Policies&lt;/h2&gt;&lt;p&gt;Validating admission policies allow administrators to define custom validation rules for resources being created in the cluster. These rules can be defined using a custom resource definition (CRD) called &amp;quot;ValidatingWebhookConfiguration&amp;quot; and are enforced by the ValidatingAdmissionWebhook admission controller.&lt;/p&gt;&lt;p&gt;For example, an administrator may want to enforce a policy that requires all pods in the cluster to have a specific label. They can define this rule using a ValidatingWebhookConfiguration CRD and configure the ValidatingAdmissionWebhook admission controller to enforce it. Any request to create a pod that does not have the required label will be rejected by the admission controller.&lt;/p&gt;&lt;p&gt;Validating admission policies also allow administrators to use external webhooks to perform the validation. This can be useful when the validation logic is complex or requires access to external resources.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Validating admission policies is a new feature in Kubernetes that allows administrators to define custom validation rules for resources being created in the cluster. These rules can be enforced using the ValidatingAdmissionWebhook admission controller, and external webhooks can also be used for complex validation logic. This feature can be useful for enforcing policies and ensuring compliance in a Kubernetes cluster.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[The Most Innovative Cloud Management Companies]]></title><link>https://layer5.io/company/news/the-most-innovative-cloud-management-companies</link><guid isPermaLink="false">https://layer5.io/company/news/the-most-innovative-cloud-management-companies</guid><dc:creator><![CDATA[Best Startup Texas]]></dc:creator><pubDate>Wed, 11 Jan 2023 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/bc8c3bab97b6d1c1577838cfae767899/best-startup-texas.jpeg" length="0" type="image/jpeg"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 DQvaY&quot;&gt;&lt;p&gt;Layer5 is featured as one of the most innovative cloud management companies by Best Startup Texas. Out of 100,000 Texas-based startups, Layer5 was selected based on oustanding marks in the following categories:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Company track record&lt;/li&gt;&lt;li&gt;Executive leadership&lt;/li&gt;&lt;li&gt;Market share&lt;/li&gt;&lt;li&gt;Innovation&lt;/li&gt;&lt;li&gt;ESG rating&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Learn more about &lt;a href=&quot;/about&quot;&gt;Layer5&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Terraform with Meshery]]></title><description><![CDATA[Terraform Infrastructure as Code with Meshery]]></description><link>https://layer5.io/resources/cloud-native/terraform-with-meshery</link><guid isPermaLink="false">https://layer5.io/resources/cloud-native/terraform-with-meshery</guid><dc:creator><![CDATA[Gaurav Chadha]]></dc:creator><pubDate>Thu, 22 Dec 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/895ec8ea35cf68449389f73e4285cb39/terraform-color.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt;Terraform is a powerful tool that helps users manage and provision infrastructure resources in a consistent and efficient manner. With Terraform, you can define your infrastructure as code, using human-readable configuration files that can be versioned, shared, and reused. This makes it easy to create, modify, and manage your infrastructure resources, whether they are cloud-based or on-premises.&lt;/p&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;One way to further enhance your use of Terraform is by integrating it with Meshery. Meshery is a cloud-native management platform that provides a unified interface for managing and monitoring your infrastructure resources, including those managed by Terraform. By integrating Terraform with Meshery, you can leverage the power and flexibility of both tools to streamline your infrastructure management process.&lt;/p&gt;&lt;p&gt;One of the key benefits of using Terraform with Meshery is the ability to manage and monitor infrastructure resources in a consistent and centralized manner. With Meshery, you can view and manage all of your infrastructure resources, whether they are managed by Terraform or other tools, from a single dashboard. This allows you to quickly identify any issues or potential problems with your infrastructure, and take action to resolve them in a timely manner.&lt;/p&gt;&lt;p&gt;Another benefit of using Terraform with Meshery is the ability to automate your infrastructure management process. With Meshery, you can create and manage automated pipelines for provisioning and managing your infrastructure resources. This can help to reduce the time and effort required to manage your infrastructure, and allow you to focus on other important tasks.&lt;/p&gt;&lt;p&gt;In addition to these benefits, using Terraform with Meshery also provides a number of other advantages. For example, Meshery integrates with a wide range of tools and platforms, allowing you to easily incorporate your existing infrastructure resources into your management process. This can help to reduce the complexity of managing your infrastructure, and make it easier to keep everything running smoothly.&lt;/p&gt;&lt;p&gt;Overall, the use of Terraform with Meshery can help to streamline and improve your infrastructure management process. By integrating these two powerful tools, you can gain greater visibility and control over your infrastructure resources, and automate many of the tasks involved in managing them. This can help to reduce the time and effort required to manage your infrastructure, and allow you to focus on other important tasks. So, it is a good idea to use Terraform with Meshery to improve the efficiency and effectiveness of your infrastructure management process.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Kubernetes 1.26 Highlights, Features, and Deprecations]]></title><description><![CDATA[Release Notes: What changed in Kubernetes 1.26?]]></description><link>https://layer5.io/blog/kubernetes/kubernetes-126-highlights-features-and-deprecations</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/kubernetes-126-highlights-features-and-deprecations</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Tue, 06 Dec 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/0cda4651daf491c6b40dd404799ca32c/kubernetes-new.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;As the final Kubernetes release of 2022, Kubernetes 1.26 is an exciting new release of the popular container orchestration platform. It offers a number of new features and improvements that will help platform engineers and DevOps engineers manage their Kubernetes clusters more effectively. Here are some of the highlights of this release.&lt;/p&gt;&lt;div class=&quot;intro&quot;&gt;&lt;p&gt;As a longstanding CNCF member, Layer5 has donated two of its open source projects to the CNCF: &lt;a href=&quot;/cloud-native-management/meshery&quot;&gt;Meshery&lt;/a&gt; and &lt;a href=&quot;/projects/cloud-native-performance&quot;&gt;Service Mesh Performance&lt;/a&gt;. As an end-to-end, open-source, multi-cluster Kuberentes management platform, Meshery makes Day 2 Kubernetes cluster management a breeze. Run Meshery to explore the behavorial changes of this Kubernetes release and what they really mean to you.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;While there are a number of enhancments tracked in this release (38), you need to be aware that there are also a number of features being deprecated (10) in 1.26. In this article, we will focus on some highlighted enhancements, important deprecations, and removals so that you can be confident before upgrading your clusters. &lt;/p&gt;&lt;p&gt;We&amp;#x27;ll breakdown new K8s features by category, starting with networking.&lt;/p&gt;&lt;h2&gt;Networking in Kubernetes 1.26&lt;/h2&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/2086&quot;&gt;Service Internal Traffic Policy&lt;/a&gt; [Stable]&lt;/h3&gt;&lt;p&gt;When requests are made to a Kubernetes service, they are randomly distributed to all available endpoints. The new enhancement enriches the API of a service to use node-local and topology-aware routing for internal traffic. The new internalTrafficPolicy field has two options: Cluster (default) and Local. The Cluster option works like before and tries distributing requests to all available endpoints. On the other hand, the Local option only sends requests to node-local endpoints and drops the request if there is no available instance on the same node. The Local option is useful for sending metrics or logs to an agent running as a DaemonSet. &lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3070&quot;&gt;Reserve Service IP Ranges for Dynamic and Static IP Allocation&lt;/a&gt; [Stable]&lt;/h3&gt;&lt;p&gt;Kubernetes services are assigned a virtual ClusterIP to be reachable inside the cluster. The ClusterIP is either assigned dynamically from a configured Service IP range, or statically set while creating the service resource. There was no possibility of knowing whether another service in the cluster had already used the static ClusterIP before this new stable enhancement. With this change, the IP range is divided into two; this prevents conflicts between services implementing dynamic IP allocation and static IP assignment. The flag --service-cluster-ip-range, with CIDR notation, is part of the Kubernetes API server configuration and is ready to use with the 1.26 release. &lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/1435&quot;&gt;Support of Mixed Protocols in Services with Type LoadBalancer&lt;/a&gt; [Stable]&lt;/h3&gt;&lt;p&gt;Kubernetes Services that use the LoadBalancer type have only supported a single Layer 4 protocol until now. With this enhancement going from graduating to stable in v1.26, it is possible to define a mix of protocols in the same service definition. In other words, this enhancement allows a LoadBalancer Service to serve different protocols (e.g. UDP, TCP) under the same port (e.g. 443). For example, serving both UDP and TCP requests for a DNS or SIP server on the same port. For instance, you can expose a DNS server with a single load balancer IP for both TCP and UDP requests, such as the following:&lt;/p&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC&quot;&gt;&lt;button class=&quot;CodeBlock__CopyCode-sc-4qx7vm-2 eEbfDY&quot;&gt;Copy&lt;/button&gt;&lt;pre class=&quot;CodeBlock__Pre-sc-4qx7vm-0 gDUqQC prism-code language-yaml&quot; style=&quot;color:#d6deeb;background-color:#011627&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; v1&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Service&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; multi&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;dns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;server&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; LoadBalancer&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; dns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;udp&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token number&quot; style=&quot;color:rgb(247, 140, 108)&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; UDP&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; dns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;tcp&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token number&quot; style=&quot;color:rgb(247, 140, 108)&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; TCP&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;CodeBlock__LineNo-sc-4qx7vm-1 kjXyGE&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;token key atrule&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; dns&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;server&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;h2&gt;Security in Kubernetes 1.26&lt;/h2&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/2133&quot;&gt;kubelet Credential Provider&lt;/a&gt; [Stable]&lt;/h3&gt;&lt;p&gt;The kubelet agent has a built-in credential provider mechanism to retrieve credentials for container image registries. It natively supports Azure, Google Cloud, and AWS container image registries for dynamically retrieving their credentials. The new stable enhancement in v1.26 offers a replacement for the in-tree implementations, and creates an API for extensible plugins in the future. &lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3031&quot;&gt;SignedSigning Release Artifacts&lt;/a&gt; [Beta]&lt;/h3&gt;&lt;p&gt;Every Kubernetes release produces a set of artifacts such as binaries, container images, documentation, and metadata. Since the 1.24 release, the artifacts have been signed as an alpha feature. In the 1.26 release, artifact signing graduates to beta to increase software supply chain security for the Kubernetes release process and mitigate man-in-the-middle attacks.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/2799&quot;&gt;Reduction of Secret-Based Service Account Tokens&lt;/a&gt; [Beta]&lt;/h3&gt;&lt;p&gt;&lt;code&gt;BoundServiceAccountTokenVolume&lt;/code&gt; has been GA since version 1.22: Service account tokens for pods are obtained via the TokenRequest API and stored as a projected volume. The new enhancement, in beta, eliminates the need to auto-generate secret-based service account tokens. In addition, Kubernetes will warn about using auto-created secret-based service account tokens, and purge the unused ones.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/1981&quot;&gt;Windows Privileged Containers&lt;/a&gt; [Stable] and &lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3503&quot;&gt;Host Networking&lt;/a&gt; [Alpha]&lt;/h3&gt;&lt;p&gt;Privileged containers are the ones that have similar access and capabilities to the host processes running on the servers. In Linux environments, they are used heavily in Kubernetes for storage, networking, and management. In this release, support for privileged containers for the Windows environment graduates to stable. Management of processes is heavily different from the operating system standpoint in Linux and Windows. Therefore, privileged containers will also work differently in two environments, but they will ensure the same level of security and operational experience.&lt;/p&gt;&lt;p&gt;In addition, there is a new alpha-level enhancement in this release to support host networking for Windows pods. Currently, Windows has all the functionality to make containers use the networking namespace of the nodes. The new alpha enhancement enables this functionality from the Kubernetes side, increasing the parity between Linux and Windows containers.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/33250&quot;&gt;Self-User Attribute and Authentication API&lt;/a&gt; [Alpha]&lt;/h3&gt;&lt;p&gt;Kubernetes has no resources to identify and manage users as part of its API. Instead, it uses authenticators to get user attributes from tokens, certificates, OIDC providers, or webhooks. The new alpha feature adds a new API endpoint to see what attributes the current users have. The new API is under authentication.k8s.io with the name SelfSubjectReview, and there is a new corresponding command as well: kubectl auth who-am-i. The new feature will reduce the obscurity of complex authentication and help users debug the authentication stack. &lt;/p&gt;&lt;h2&gt;Scheduling in Kubernetes 1.26&lt;/h2&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/2268&quot;&gt;Non-Graceful Node Shutdown for StatefulSet Pods&lt;/a&gt; [Beta]&lt;/h3&gt;&lt;p&gt;As a platform Kubernetes is hardened and has been deploy by thousands and thousands of users. Hardening of Kubernetes makes itself resistant to disasters. The kubelet agent that runs on each node in a Kubernetes cluster already uses graceful node shutdown to detect and offboard workloads to other nodes. However, when the shutdown is not detected by the kubelet, the pods of a &lt;code&gt;StatefulSet&lt;/code&gt; are stuck as &lt;code&gt;Terminating&lt;/code&gt; and not transferred to a healthy node. The kubelet on the downed node will not delete its pods from Kubernetes API, and the StatefulSet controller will not create new pods with the same name. This happens due to a conflict in the Kubernetes machinery. With this enhancement moving into beta, though, pods will be forcefully deleted along with their volume attachments and new pods will be migrated (created) on healthy nodes.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3521&quot;&gt;Pod Scheduling Readiness&lt;/a&gt; [Alpha]&lt;/h3&gt;&lt;p&gt;Currently, pods are considered ready for scheduling as soon as they are created. However, not every pod requires a node, resource allocation, and the start of all its containers immediately after its creation. The new alpha enhancement adds an API to mark pods with their scheduling status: paused and ready. Pods with the .spec.schedulingGates field will be parked in the scheduler and only be assigned to nodes when they are ready to be scheduled.&lt;/p&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/3515&quot;&gt;kubectl explain to use OpenAPI v3 for &lt;/a&gt; [Alpha]&lt;/h3&gt;&lt;p&gt;Use of OpenAPI v3 means supporting rich type information in &lt;code&gt;kubectl explan&lt;/code&gt;. Kubernetes has supported OpenAPI v3 as a beta since version 1.24. This richer representation of the fields in the Kubernetes API, means that users can use the &lt;code&gt;kubectl explain&lt;/code&gt; command to get information that is only detailed in  OpenAPI v3, and not the subset defined OpenAPI v2.&lt;/p&gt;&lt;h2&gt;Deprecations and Removals&lt;/h2&gt;&lt;p&gt;Consistent to the Kubernetes API lifecycle is deprecations and removals of APIs in each release. It is strongly suggested to check whether you are using the following APIs and flags before there are breaking changes.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Removal of the `flowcontrol.apiserver.k8s.io/v1beta1` API group for `FlowSchema` and `PriorityLevelConfiguration` requires a migration to the v1beta2 API version.&lt;/li&gt;&lt;li&gt;Removal of the `autoscaling/v2beta2` API version for HorizontalPodAutoscaler requires a migration to the autoscaling/v2 API version.&lt;/li&gt;&lt;li&gt;Removal of legacy and vendor-specific authentication client-go and kubectl for Azure and Google Cloud requires migration to vendor-neutral authentication plugin mechanisms.&lt;/li&gt;&lt;li&gt;Removal of in-tree CSI integration for OpenStack—namely, the `cinder` volume type—requires a migration to use the CSI driver for OpenStack.&lt;/li&gt;&lt;li&gt;Some unused options and flags for the kubectl run command are marked as deprecated in the 1.26 release, such as `--grace-period`, `--timeout`, and `--wait`.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Last Kubernetes release of 2022&lt;/h2&gt;&lt;p&gt;Kubernetes is an ever-evolving platform. For those of you running workloads on Kubernetes taking detailed note of API changes and enhancements is an important activity as you endevour to keep your clusters upgraded with release releases. A more secure, scalable, and flexible Kubernetes is our collective goal. Dign into more details about deprecation, removals, and the latest changes in the 1.26 &lt;a href=&quot;https://relnotes.k8s.io/&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;On behalf of the Layer5 community and all of the CNCF projects that its contributors steward, thank you to everyone who participated in this Kubernetes release, and congratulations! &lt;/p&gt;&lt;p&gt;As an end-to-end, open-source, multi-cluster Kuberentes management platform, Meshery makes Day 2 Kubernetes cluster management a breeze. Run Meshery to explore the behavorial changes of this Kubernetes release and what they really mean to you. &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Structured logging in Kubernetes with Klog]]></title><description><![CDATA[Structured logging in Kubernetes 1.26 with Klog]]></description><link>https://layer5.io/blog/kubernetes/structured-logging-in-kubernetes-with-klog</link><guid isPermaLink="false">https://layer5.io/blog/kubernetes/structured-logging-in-kubernetes-with-klog</guid><dc:creator><![CDATA[Lee Calcote]]></dc:creator><pubDate>Mon, 05 Dec 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/a125a7ad56dafd70886f09d8c408e114/kubernetes-logs.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Blogstyle__BlogWrapper-sc-di69nl-0 ebZMcE&quot;&gt;&lt;p&gt;As a platform for developers and system administrators to easily deploy and manage applications in a distributed environment, Kubernetes clusters generate logs and lots of them. One of the key components of Kubernetes is its logging and instrumentation capabilities. The upcoming Kubernetes 1.26 release has a handful of noteworthy changes to its system component logger, &lt;code&gt;klog&lt;/code&gt;.&lt;/p&gt;&lt;h2&gt;Kubernetes System Log&lt;/h2&gt;&lt;p&gt;System component logs record events happening in K8s clusters. More than metrics or traces, logs are the telemetric signal often found to be most useful for debugging. You can configure K8s log verbosity to see more or less detail. Logs can be as coarse-grained as showing errors within a component, or as fine-grained as showing step-by-step traces of events (like HTTP access logs, pod state changes, controller actions, or scheduler decisions).&lt;/p&gt;&lt;h2&gt;Klog&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/kubernetes/klog&quot;&gt;klog&lt;/a&gt; is a Kubernetes logging library that provides an API for developers and system administrators to instrument their applications for logging and tracing. klog generates log messages for the Kubernetes system components. It provides a comprehensive set of features, including log levels, structured logging and logging context.&lt;/p&gt;&lt;p&gt;Kubernetes 1.23 introduced structured logging (in beta) in &lt;code&gt;klog&lt;/code&gt;. Structured logging is a uniform structure in log messages allowing for programmatic extraction of information. Structured logs can be stored and processed with less effort and cost. The code which generates a log message determines whether it uses the traditional unstructured &lt;code&gt;klog&lt;/code&gt; output or structured logging.&lt;/p&gt;&lt;p&gt;As a dependency to structured logging (gated behind &lt;code&gt;StructuredLogging&lt;/code&gt; feature gate), Kubernetes 1.24 introducted contextual logging (in alpha) in &lt;code&gt;klog&lt;/code&gt;. Contextual logging builds on top of structured logging. It is primarily about how developers use logging calls: code based on that concept is more flexible and supports additional use cases which will be the topic of a future blog post. &lt;/p&gt;&lt;h3&gt;Klog Deprecations in Kubernetes 1.26&lt;/h3&gt;&lt;p&gt;Kubernetes has recently announced that it intends to deprecate certain flags related to Klog in its components. This means that Klog-specific flags, such as &lt;code&gt;--klog-verbosity&lt;/code&gt;, &lt;code&gt;--klog-vmodule&lt;/code&gt; and &lt;code&gt;--klog-stderrthreshold&lt;/code&gt; will no longer be supported. This is due to the fact that Klog has been largely superseded by the more comprehensive OpenTelemetry project, which provides a more complete solution for logging and instrumentation.&lt;/p&gt;&lt;p&gt;The deprecation of Klog-specific flags is a positive step forward for Kubernetes as it moves to OpenTelemetry. This move will ensure that Kubernetes is using the industry-standard logging and instrumentation solution. It will also provide developers and system administrators with a more comprehensive, reliable and consistent experience when instrumenting their applications.
A goal of this deprecation is one of unblocking development of alternative logging formats. Why does Kubnernetes need another logging format? One reason is performance. Klog performance is much worse than alternatives, for example 7-8x than JSON format:&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;logger&lt;/th&gt;&lt;th&gt;time [ns/op]&lt;/th&gt;&lt;th&gt;bytes[B/op]&lt;/th&gt;&lt;th&gt;allocations[alloc/op]&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Text Infof&lt;/td&gt;&lt;td&gt;2252&lt;/td&gt;&lt;td&gt;248&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Text InfoS&lt;/td&gt;&lt;td&gt;2455&lt;/td&gt;&lt;td&gt;280&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;JSON Infof&lt;/td&gt;&lt;td&gt;1406&lt;/td&gt;&lt;td&gt;19&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;JSON InfoS&lt;/td&gt;&lt;td&gt;319&lt;/td&gt;&lt;td&gt;67&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Proof of concept implementation of new logging formats were completed to assess the potentional gains of using an alternative format. Results measured on 30s benchmark for passing 2 arguments to format function.&lt;/p&gt;&lt;div class=&quot;tip&quot;&gt;&lt;h3&gt;Tip: Logger Performance Comparison&lt;/h3&gt;&lt;p&gt;Interestingly, Klog isn&amp;#x27;t the fastest logger in the West, but Uber&amp;#x27;s open source project &lt;a href=&quot;https://github.com/uber-go/zap&quot;&gt;zap &lt;/a&gt; appears to hold that title instead. The following performance test benchmark is an examle of one of a number of scenarios in which loggers can be performance analyzed.&lt;/p&gt;&lt;p&gt;Log a message and 10 fields:&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Package&lt;/th&gt;&lt;th align=&quot;center&quot;&gt;Time&lt;/th&gt;&lt;th align=&quot;center&quot;&gt;Time % to zap&lt;/th&gt;&lt;th align=&quot;center&quot;&gt;Objects Allocated&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;zap&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2900 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+0%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;5 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;zap (sugared)&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;3475 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+20%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;10 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;zerolog&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;10639 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+267%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;32 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;go-kit&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;14434 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+398%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;59 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;logrus&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;17104 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+490%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;81 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;apex/log&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;32424 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+1018%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;66 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;log15&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;33579 ns/op&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;+1058%&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;76 allocs/op&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt;Output will always be written to stderr, regardless of the output format. Output redirection is expected to be handled by the component which invokes a Kubernetes component. This can be a POSIX shell or a tool like systemd.&lt;/p&gt;&lt;p&gt;The deprecation of Klog-specific flags is part of a larger effort to transition Kubernetes to a more modern and comprehensive logging and instrumentation solution. This will provide Kubernetes users with a more reliable, secure and consistent experience when instrumenting and monitoring their applications.&lt;/p&gt;&lt;p&gt;Kubernetes will continue to provide support for Klog-specific flags for the foreseeable future. However, it is recommended that developers and system administrators begin transitioning their applications to the OpenTelemetry framework. This will ensure that their applications are using the industry-standard solution for logging and instrumentation.&lt;/p&gt;&lt;p&gt;Overall, the deprecation of Klog-specific flags is a positive step forward for Kubernetes. It will ensure that Kubernetes users have access to the most reliable and comprehensive solution for logging and instrumentation. It will also help ensure that Kubernetes is using the industry-standard solution and will provide developers and system administrators with a more reliable and consistent experience when instrumenting their applications.&lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Management of Kubernetes]]></title><description><![CDATA[Management of Kubernetes]]></description><link>https://layer5.io/resources/kubernetes/management-of-kubernetes</link><guid isPermaLink="false">https://layer5.io/resources/kubernetes/management-of-kubernetes</guid><dc:creator><![CDATA[Tolulope Ola-David]]></dc:creator><pubDate>Mon, 21 Nov 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/9287b4a708bb510f64057ea305498b77/kubernetes-logo.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;h3&gt; What is Kubernetes Management, and Why Should You Care? &lt;/h3&gt;&lt;p&gt; It is easy to understand why Kubernetes has become one of the most popular tools on the market today. Primarily, it allows you to easily manage Docker containers across your entire infrastructure with very little overhead, making it easier than ever to manage massive amounts of information in a timely manner. But what are you supposed to do with all this information? That’s where Kubernetes management comes into play—the process of using that information in an effective manner can make or break your efforts, so it’s essential that you choose the right solutions from the get-go.&lt;/p&gt;&lt;h3&gt; Defining Kubernetes management &lt;/h3&gt;&lt;p&gt; Kubernetes management is the process of managing your containers on a Kubernetes cluster. This can include things like adding or removing clusters, scaling clusters up or down, balancing workloads across nodes in a cluster, and restarting failed containers or nodes in a cluster. These tasks are complicated and involve many different types of actions. Figuring out how to do them all manually would be extremely time-consuming. Fortunately, there are tools like Meshery that automate these tasks for you, making it easier to see what’s going on within your cluster so you can make informed decisions about what needs to happen next. Staying on top of Kubernetes management will not only keep your cluster running smoothly but also help prevent problems before they occur. Automating this process will save you time and money, leaving more time to focus on other aspects of the business. When things go wrong, automated Kubernetes management allows you to have a plan and know exactly what steps need to be taken to recover from an incident. With these benefits in mind, it’s important that companies with containerized infrastructure use some type of automation for their Kubernetes management.&lt;/p&gt;&lt;h3&gt; The benefits of Kubernetes management &lt;/h3&gt;&lt;p&gt; Kubernetes management can seem like a daunting task. In the past, IT teams had to worry about maintaining large clusters of machines that required constant tweaking and monitoring. Kubernetes simplifies this process by automating tasks such as:&lt;ul&gt;&lt;li&gt; Monitoring cluster health &lt;/li&gt;&lt;li&gt; Deploying apps across nodes &lt;/li&gt;&lt;li&gt; Running rolling updates &lt;/li&gt;&lt;li&gt; Scaling up or down resources on demand &lt;/li&gt;&lt;li&gt; Auto-recover from failures &lt;/li&gt;&lt;li&gt; Application deployment consistency &lt;/li&gt;&lt;li&gt; Managing container upgrades &lt;/li&gt;&lt;/ul&gt;After reading through these benefits, you may be asking yourself, &amp;quot;Why should I care? Here are two reasons why you should care about Kubernetes management: - Kubernetes management has been shown to improve software development efficiency because it reduces time spent waiting for containers to restart and redeploy. A recent study showed that developers using Kubernetes were able to deploy new code changes at least 27% faster than developers without any container orchestration solution.&lt;/p&gt;&lt;blockquote&gt; Developers using Kubernetes were able to deploy new code changes at least 27% faster than developers without any container orchestration solution. &lt;/blockquote&gt;&lt;p&gt; Kubernetes management has also been shown to reduce operational costs because it eliminates the need for manual intervention in scaling applications, updating running containers with new versions, etc. If your IT team was spending 10 hours per week on manual operations before adopting Kubernetes, they&amp;#x27;ll spend only 2 hours after switching over! &lt;/p&gt;&lt;div class=&quot;CTA_FullWidth__CTA_FullWidthWrapper-sc-1rsxguj-0 yZijj get-start-kubernetes-resource&quot;&gt;&lt;img src=&quot;/static/multi-cluster-kubernetes-management-with-meshery-21f7b4f3cce3b8315ba9474f874cdd52.webp&quot; alt=&quot;Multi-Cluster Kubernetes Management with Meshery&quot;/&gt;&lt;div class=&quot;cta-content&quot;&gt;&lt;div&gt;&lt;h3&gt;Layer5 Community&lt;/h3&gt;&lt;p&gt;Multi-Cluster Kubernetes Management with Meshery&lt;/p&gt;&lt;/div&gt;&lt;a href=&quot;/blog/meshery/multi-cluster-kubernetes-management-with-meshery&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 kpjYoD appion__btn&quot; title=&quot;Read blog post&quot;&gt; Read blog post&lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;h3&gt; The challenges of Kubernetes management &lt;/h3&gt;&lt;p&gt; Kubernetes management can seem like a difficult endeavour. Between determining how to automate deployment and scaling and comprehending the fundamentals of how it operates, there are numerous factors to consider. Fortunately, there are numerous frameworks that simplify this procedure. But before going into new frameworks or technologies, you must grasp what Kubernetes administration comprises so that you know what you&amp;#x27;re attempting to automate. Kubernetes management comprises a variety of activities, such as building up clusters, keeping apps running on those clusters up-to-date, monitoring usage and providing alarms to keep things running smoothly, and shutting down clusters when they are no longer required. &lt;/p&gt;&lt;p&gt; There are numerous ways to manage these tasks: manually, with containers, with an orchestration system such as Ansible Tower, Cloud Control 12c, or ServiceNow NMS, with containers-as-a-service providers such as Docker Datacenter or AWS EKS, with container service offerings from cloud providers such as Azure Container Instances, by configuring Kubernetes with your own framework, and by installing Kubectl on your laptop for direct control. Each strategy has advantages and disadvantages that may make one more suitable for your organisation than another. Regardless of the approach you adopt, you must plan accordingly. &lt;/p&gt;&lt;p&gt; Importantly, the fact that Kubernetes is gaining popularity does not imply that it will replace your existing infrastructure layers. It augments their capabilities with scalability and large-scale application management (which would have been difficult without automation). In addition, the definition of management varies based on the size of the organisation: small businesses may prefer self-hosted platforms, whilst larger businesses would often primarily rely on SaaS solutions. &lt;/p&gt;&lt;h3&gt; How Meshery makes it easier to run Kubernetes &lt;/h3&gt;&lt;p&gt; Meshery is the only cloud-native manager in the world that supports more adapters than any other project or product. &lt;/p&gt;&lt;img src=&quot;/static/meshery-core-architecture-ada2489fcafbb125bde85de34ba3116e.webp&quot; class=&quot;image-center&quot; alt=&quot;Management of Kubernetes with Meshery&quot;/&gt;&lt;p&gt; Meshery has been designed for the world of many service meshes and many Kubernetes clusters. As such, great attention was made to guarantee that it is an extensible management platform, able to handle a diverse range of infrastructure and new use cases quickly through its plugin mechanism. Meshery Server acts as an operation delegator, determining which Meshery Adapter has registered its capacity for the given operation. The operation is then sent to the appropriate component using a gRPC call. This could be one of Meshery&amp;#x27;s service mesh adapters, like the Istio adapter. &lt;/p&gt;&lt;p&gt; Meshery&amp;#x27;s capability is constantly expanding, from multi-mesh to now multi-cluster, to give developers, operators, and security engineers more control over their infrastructure. Each part of Meshery&amp;#x27;s architecture makes a big difference in how it manages multiple Kubernetes clusters. &lt;/p&gt;&lt;h3&gt; Meshery management across many clusters &lt;/h3&gt;&lt;p&gt; From the settings page, users can do things related to clusters, like add more clusters, remove data from existing clusters, or delete existing clusters. &lt;/p&gt;&lt;img src=&quot;/static/settings-ad3405d125c81cc83695f10d49b51ae3.webp&quot; class=&quot;image-center&quot; alt=&quot;Management of Kubernetes with Meshery&quot;/&gt;&lt;p&gt; Meshery also deploys Meshery operators throughout the cluster it is about to manage. This operator is in charge of the Meshery broker and the MeshSync lifecycle. MeshSync is responsible for monitoring various types of resources by establishing a watch stream over each of them. MeshSync then sends the data to the NATS server, of which the Meshery server is a client. Meshery server then receives all necessary data relating to cluster activity. &lt;/p&gt;&lt;img src=&quot;/static/context-switcher-dcf6363d7932bb835366e0bd322d32c9.webp&quot; class=&quot;image-center&quot; alt=&quot;Management of Kubernetes with Meshery&quot;/&gt;&lt;p&gt; Meshery, by default, wants to be as aware of your infrastructure as possible in order to deliver value. As such, it deploys its operator across each identified cluster. However, you can fine-tune this configuration by going over each one. &lt;/p&gt;&lt;h3&gt; The future of Kubernetes management &lt;/h3&gt;&lt;p&gt; Kubernetes management has been one of the buzzwords since 2018. But what does it actually mean? And why should you care about it? At its core, Kubernetes management is a system that helps make sense of the nuances of how different containers work together to create an application. As we rely more on containers for our everyday apps, there needs to be a way to keep track of them all. That&amp;#x27;s where Kubernetes comes in with its ability to manage these containers that are spread out across different servers and understand which ones need more resources or want to be shut down because they&amp;#x27;re no longer needed. The easier it becomes for developers and engineers to deploy applications without worrying about how they are going to be managed, the better off everyone will be. Fortunately, as containerization grows in popularity among developers and IT teams alike, so does the number of tools for managing it. &lt;/p&gt;&lt;p&gt; A lot of container platforms provide native management functionality: Docker Swarm allows you to use simple commands like swarm stop or swarm pull when your swarm is up-to-date; Kargo automatically manages clusters using zero-touch configuration; Rancher provides tools to manage containers using any infrastructure stack; and Mesos offers both orchestration capabilities through Marathon as well as advanced resource scheduling features. It&amp;#x27;s not always easy to know which platform will work best for your organization, but it&amp;#x27;s important to find one that suits your company&amp;#x27;s needs—especially if IT is looking forward to a future without manual management tasks! &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Getting Started with Kubernetes]]></title><description><![CDATA[Introduction to Kubernetes]]></description><link>https://layer5.io/resources/kubernetes/getting-started-with-kubernetes</link><guid isPermaLink="false">https://layer5.io/resources/kubernetes/getting-started-with-kubernetes</guid><dc:creator><![CDATA[Tolulope Ola-David]]></dc:creator><pubDate>Wed, 02 Nov 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/b1a646c34f1a9ed49dcf37dd7b9b4662/kubernetes-logo.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt; Kubernetes, an open-source container orchestration platform, is growing in popularity for deploying and managing cloud-native applications. Kubernetes was created by Google in 2014, and it is now used by many major companies, including IBM, Microsoft, Red Hat, and Amazon. In this article, we&amp;#x27;ll talk about Kubernetes, its benefits, and the best ways for your organization to use it.&lt;/p&gt;&lt;h3&gt; What is Kubernetes? &lt;/h3&gt;&lt;p&gt; Kubernetes offers fully managed and adapted architecture services that optimize your cloud-native application. Kubernetes is a platform that hides virtual machines, shows the infrastructure as an infrastructure-as-a-service (IAAS), network, and load balancer, and offers data storage and operations that are consistent across containers.&lt;/p&gt;&lt;p&gt; For example, Kubernetes nodes work as Kubernetes containers, such as an application, an application server, and control processes in Docker containers. Kubernetes components such as Kubernetes nodes and Kubernetes containers can be defined or modified via configuration files or can be specified subsequently. Individual Kubernetes components can be scaled according to elasticity needs to optimize performance.&lt;/p&gt;&lt;p&gt; Kubernetes optimizes a Kubernetes environment in the cloud, Docker containers on a system for development or testing, and the master or control plane of its cloud cluster management infrastructure.&lt;/p&gt;&lt;h3&gt; What&amp;#x27;s the Difference between Kubernetes and Docker? &lt;/h3&gt;&lt;p&gt; Over the past few years, containers have become increasingly popular within the software development community, and they have now evolved into two major platforms — Docker and Kubernetes. Both are incredibly powerful tools that allow developers to containerize their applications, but they are also slightly different in a number of ways, with more differences on the horizon as Docker announces its new focus on Kubernetes and containers orchestration. How do you decide which one to use? What does the future hold for each? Here’s what you need to know about the difference between Docker and Kubernetes.&lt;/p&gt;&lt;p&gt; Docker is an open-source platform designed to help developers and IT professionals create, deploy, and run applications. This containerization technology is often used in conjunction with orchestration software such as Kubernetes. However, these two technologies are not interchangeable; they serve different purposes. &lt;/p&gt;&lt;h3&gt; Why Should You Care About Kubernetes? &lt;/h3&gt;&lt;p&gt; Kubernetes was first made available for Google&amp;#x27;s internal use for DNS hosting. Open-source software projects were not able to use it. &lt;/p&gt;&lt;p&gt; Today, Kubernetes is in use by large-scale companies that use container orchestration. And in January 2019, The New Stack reported that a survey conducted in that month, which included the Kubernetes user group, discovered that Kubernetes reached more than 40,000 users and 200 companies were working on Kubernetes at that point. In addition, Gartner indicated that Kubernetes Inc. would make some $8.5 billion in 2019. &lt;/p&gt;&lt;h3&gt; What does Kubernetes Do? &lt;/h3&gt;&lt;p&gt; In contrast to an overall infrastructure, Kubernetes is a dynamic layer-oriented computing infrastructure. The essence of Kubernetes is how an entire infrastructure hops! Kubernetes is a container orchestration and management platform that has built-in features for self-replication, elasticity, and scalability. Through these and more features, Kubernetes &amp;quot;promovi-is&amp;quot; for container orchestrators for both production and lab environments. &lt;/p&gt;&lt;h3&gt; Kubernetes Architecture &lt;/h3&gt;&lt;p&gt; Even though Kubernetes is a software platform that lets organizations manage their application workloads in containers, a traditional Kubernetes cluster may not be the best solution for a number of business needs. &lt;/p&gt;&lt;img src=&quot;/static/meshery-core-architecture-ada2489fcafbb125bde85de34ba3116e.webp&quot; class=&quot;image-center&quot; alt=&quot;Kubernetes Architecture&quot;/&gt;&lt;p&gt; A cluster of virtual computing resources is only one option, and it has its drawbacks. What happens when you lose disk space (which can happen if you don&amp;#x27;t add new containers, users, or workloads to a cluster)? Do you have another cluster for redundancy, and how do you integrate the two together? &lt;/p&gt;&lt;p&gt; Hyperconverged infrastructures like Red Hat OpenShift are an alternative that combine several technologies into a single virtual machine or physical machine. &lt;/p&gt;&lt;h3&gt; Best Practices for Kubernetes &lt;/h3&gt;&lt;p&gt; Kubernetes is a container orchestration platform created by Google in 2014. It provides a way for companies to build fully self-sufficient, scalable, multi-container applications every time they need to deploy and manage their own containers. It&amp;#x27;s aimed at pretty much the same audience as Docker and other container orchestration platforms—that is, organizations that run containerized applications and want to deploy scalable, repeatable deployments.&lt;/p&gt;&lt;p&gt; At the most basic and most simplistic level, a group of containers (usually 16) is cross-linked together in a cluster, based on Docker. Containers run inside a cluster of virtual machines (Kubernetes VM) as a single Linux file system. Kubernetes organizes the creation, deletion, and management of containers into container concepts that provide fault tolerance, availability, scaling, permission management, and secure containers that should be able to run together and share resources. Each host runs one or more containers, providing the abstraction of which containers can run on which hosts.&lt;/p&gt;&lt;p&gt; Since Kubernetes services are usually very easy to use, the user experience is very similar to that of centralized solutions. &lt;/p&gt;&lt;p&gt; With Kubernetes, businesses can make data repositories and containers, federate their resources in an efficient way, manage billing, certify capacity, quota, access rights, and more. &lt;/p&gt;&lt;p&gt; It can scale to many nodes simultaneously, so when their machines scale up, then their containers could scale up too. &lt;/p&gt;&lt;h3&gt; Kubernetes Concepts and Terminology &lt;/h3&gt;&lt;p&gt; Kubernetes was developed in 2014 as a Google container orchestrator, a container scheduler and more. Kubernetes was created to manage distributed applications, including Docker containers. According to SUSE, Kubernetes is simple to learn, easy to manage, and supports an on-premise, private, public, or hybrid architecture. Kubernetes is flexible enough to be split up over many servers in your data center. &lt;/p&gt;&lt;p&gt; This simplificator, one example of many, allows one to scale independent containers. &lt;/p&gt;&lt;p&gt; Let&amp;#x27;s understand better what Kubernetes is: &lt;/p&gt;&lt;p&gt; In an application ecosystem of operating system Docker containers, Kubernetes acts as a centralized management guided by distributed logic. Kubernetes can be used to deliver web traffic, graphics work, or IP traffic from IoT devices. The main benefit is that clusters can be easily expanded to a huge size with all functions. &lt;/p&gt;&lt;p&gt; What are pods? Pods are Docker instances that you can use to deploy your containers in environments like Kubernetes, which can be private, public, or a mix of the two.&lt;/p&gt;&lt;p&gt; Environments may be private services or public clouds. &lt;/p&gt;&lt;p&gt; Kubernetes can be used to manage containers because they are easy to use and make it easy to scale your containers. &lt;/p&gt;&lt;p&gt; Installation tutorials are sometimes yoinked without ever reading the help. &lt;/p&gt;&lt;h3&gt; RBAC and Firewall Security &lt;/h3&gt;&lt;p&gt; Today, everything is hackable, and so is your Kubernetes cluster. Hackers often try to find vulnerabilities in the system in order to exploit them and gain access. So, keeping your Kubernetes cluster secure should be a high priority. The first thing to do is make sure you are using RBAC in Kubernetes. RBAC is role-based access control. Assign roles to each user in your cluster and to each service account running in your cluster. Roles in RBAC contain several permissions that a user or service account can perform. You can assign the same role to multiple people, and each role can have multiple permissions.&lt;/p&gt;&lt;p&gt; RBAC settings can also be applied to namespaces, so if you assign roles to a user allowed in one namespace, they will not have access to other namespaces in the cluster. Kubernetes provides RBAC properties such as role and cluster role to define security policies. &lt;/p&gt;&lt;p&gt; You can create a firewall for your API server to prevent attackers from sending connection requests to your API server from the Internet. To do this, you can either use regular firewalling rules or port firewalling rules. If you are using something like GKE, you can use a master authorized network feature in order to limit the IP addresses that can access the API server. &lt;/p&gt;&lt;h3&gt; Managing Kubernetes Clusters &lt;/h3&gt;&lt;p&gt; Kubernetes is a project that lets you create and manage individual containers or a container cluster on a mainframe. Clusters may consist of physical, virtual, or cloud-based computing resources.&lt;/p&gt;&lt;div class=&quot;CTA_FullWidth__CTA_FullWidthWrapper-sc-1rsxguj-0 yZijj get-start-kubernetes-resource&quot;&gt;&lt;img src=&quot;/static/multi-cluster-kubernetes-management-with-meshery-21f7b4f3cce3b8315ba9474f874cdd52.webp&quot; alt=&quot;Multi-Cluster Kubernetes Management with Meshery&quot;/&gt;&lt;div class=&quot;cta-content&quot;&gt;&lt;div&gt;&lt;h3&gt;Layer5 Community&lt;/h3&gt;&lt;p&gt;Multi-Cluster Kubernetes Management with Meshery&lt;/p&gt;&lt;/div&gt;&lt;a href=&quot;/blog/meshery/multi-cluster-kubernetes-management-with-meshery&quot;&gt;&lt;button class=&quot;btnstyle__ButtonStyle-sc-mhxpaj-0 kpjYoD appion__btn&quot; title=&quot;Read blog post&quot;&gt; Read blog post&lt;/button&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;p&gt; The Kubernetes projects auto-deploy container clusters anywhere there is a pluggable environment and an open-source base that includes system-config service, service account manager, and kubelet. So, developers and system administrators can easily put containers on a single machine or on nodes of machines in any scalable cluster to save money and time.&lt;/p&gt;&lt;p&gt; Kubernetes is an open-source system for automating the deployment, scaling, and management of containerized applications. Kubernetes was made by Google, and the Cloud Native Computing Foundation now takes care of it.&lt;/p&gt;&lt;h3&gt;Kubernetes Cluster Visualization and Designing using MeshMap&lt;/h3&gt;&lt;p&gt; MeshMap has been developed for visualizing and managing kubernetes clusters. You can learn more about MeshMap &lt;a href=&quot;https://layer5.io/cloud-native-management/meshmap&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Users can drag-and-drop your cloud native infrastructure using a pallete of thousands of versioned Kubernetes components. Integrate advanced performance analysis into your pipeline.&lt;/p&gt;&lt;img src=&quot;/static/MeshmapDesigner-e3bbc66d72dedf1345a87890103e31c0.webp&quot; class=&quot;image-center&quot; alt=&quot;Kubernetes Architecture&quot;/&gt;&lt;p&gt;Users can deploy their designs, apply patterns, manage and operate their deployments in real-time bringing all the Kubernetes clusters under a common point of management. Interactively connect to terminal sessions or initiate and search log streams from your containers.&lt;/p&gt;&lt;img src=&quot;/static/MeshmapVisualizer-7d853e953fa58d40fd3315f44ba34ba0.webp&quot; class=&quot;image-center&quot; alt=&quot;Kubernetes Architecture&quot;/&gt;&lt;h3&gt; Set Resource Requests &amp;amp; Limits&lt;/h3&gt;&lt;p&gt; Occasionally, deploying an application to a production cluster can fail due to the limited resources available on that cluster. This is a common challenge when working with a Kubernetes cluster, and it’s caused when resource requests and limits are not set. Without resource requests and limits, pods in a cluster can start utilizing more resources than required. If the pod starts consuming more CPU or memory on the node, then the scheduler may not be able to place new pods, and even the node itself may crash. Resource requests specify the minimum amount of resources a container can use. &lt;/p&gt;&lt;p&gt; For both requests and limits, it’s typical to define CPU in millicores and memory in megabytes or mebibytes. Containers in a pod do not run if the request for resources made is higher than the limit you set.&lt;/p&gt;&lt;p&gt; In this example, we have set the limit of the CPU to 800 millicores and the memory to 256 mebibytes. The maximum request which the container can make at a time is 400 millicores of CPU and 128 mebibyte of memory.&lt;/p&gt;&lt;h3&gt; Guide to Containers &lt;/h3&gt;&lt;p&gt; Containers have been around for a while, but it wasn’t until Docker came along that they really took off. In its early days, developers were using it to build their applications in containers. Now companies like Walmart are using containers to deploy their entire infrastructure.&lt;/p&gt;&lt;p&gt; Containers are lighter-weight than virtual machines because they don&amp;#x27;t need to emulate an entire operating system. This is why containers are typically faster to start up and use less resources. However, containers cannot be moved between hosts like virtual machines can, so a more robust solution may be needed for this use case.&lt;/p&gt;&lt;p&gt; Because they&amp;#x27;re so lightweight and take up less space than VMs do, containers are great for running lots of them at once! If your application needs more computing power or memory than your machine can provide on its own, using multiple containers in parallel will help balance out any resource shortages without having to invest in additional physical hardware like you would with traditional VM-based deployments.&lt;/p&gt;&lt;p&gt; As they&amp;#x27;re isolated from each other, containers are great for running multiple apps at once without worrying about them stepping all over each other&amp;#x27;s toes! This makes them perfect for things like hosting websites or email services where you want lots of different people to be able to use it at the same time without slowing down or crashing because there&amp;#x27;s not enough resources available for everyone. &lt;/p&gt;&lt;p&gt; What&amp;#x27;s more, since they&amp;#x27;re so easy to spin up and take down, they&amp;#x27;re also great for testing out new ideas quickly without having to worry about making permanent changes to your system (or losing any data along the way!). So if you want to try out a new CMS but don&amp;#x27;t want to go through the trouble of installing it on your machine first, just fire up a container with it inside and see how it goes! &lt;/p&gt;&lt;p&gt; One downside to using containers is that they can&amp;#x27;t easily be moved between hosts like virtual machines can, so a more robust solution may be needed for this use case. Fortunately, there are some great open source projects out there that help solve this problem!&lt;/p&gt;&lt;h3&gt; Conclusion &lt;/h3&gt;&lt;p&gt; Kubernetes is a popular containerization solution that continues to see increasing adoption rates. That being said, using it successfully requires thorough consideration of your workflows and departmental best practices. &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Service Mesh: Istio]]></title><description><![CDATA[Explanation of Istio]]></description><link>https://layer5.io/resources/service-mesh/service-mesh-istio</link><guid isPermaLink="false">https://layer5.io/resources/service-mesh/service-mesh-istio</guid><dc:creator><![CDATA[Deepesha Burse]]></dc:creator><pubDate>Wed, 31 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/731763d720780a49c2ffdfede8c28f4b/istio.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt; Microservice architectures offer some solutions while posing new ones. Application division into separate services makes scaling, updating, and development easier. It also provides you with a lot more moving pieces to connect and secure. It can get quite complicated to manage all of the network services, including load balancing, traffic management, authentication and authorisation, etc. &lt;/p&gt;&lt;p&gt; Istio, an open-source service mesh created by Google, IBM, and Lyft, enables you to connect, monitor, and secure microservices that are hosted on-premises, in the cloud, or with orchestration systems like Kubernetes and Mesos. The beta version of Istio was announced in the year 2018 in KubeCon on Google Cloud. &lt;/p&gt;&lt;p&gt; Before moving on to what Istio is and how it works, let us look into what service meshes are and why there was an urgent need for them as microservices started getting used more. &lt;/p&gt;&lt;h3&gt; Service Mesh &lt;/h3&gt;&lt;p&gt; A service mesh is an infrastructural layer that is used to provide secure communication between different services for on-prem, cloud or multi-cloud infrastructure. It allows us to add features like observability, traffic management, and security without having to add that to our code. The term &amp;quot;service mesh&amp;quot; refers to both the kind of software you employ to carry out this pattern and the security or network domain that results from its application. &lt;/p&gt;&lt;p&gt; Service meshes are divided into two parts: the control plane and the data plane. The control plane&amp;#x27;s responsibilities include securing the mesh, facilitating service discovery, doing regular health checks, enforcing policies, and handling other operational issues. A central registration of services and their corresponding IP addresses is referred to as service discovery. To share with other services how to communicate with it and to assist enforce rules on which services are allowed to communicate with which other services, the application must be registered on the control plane. &lt;/p&gt;&lt;p&gt; The communication between services, on the other hand, is handled by the data plane. Because many service mesh solutions use a sidecar proxy to manage data plane connections, the amount of knowledge that the services must have about the network environment is constrained. &lt;/p&gt;&lt;img src=&quot;/static/service-mesh.609aa147.svg&quot; class=&quot;image-center&quot; alt=&quot;Service Mesh&quot;/&gt;&lt;h3&gt; Inside the Istio service mesh &lt;/h3&gt;&lt;p&gt; A data plane and a control plane are logically separate parts of an Istio service mesh.&lt;ul&gt;&lt;li&gt; A group of intelligent proxies (Envoy) that are deployed as sidecars make up the data plane. All network connection among the microservices is mediated and managed by these proxies. Additionally, they gather and compile data on all mesh communications. &lt;/li&gt;&lt;li&gt; The proxies are controlled and set up by the control plane to route traffic. &lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;&lt;img src=&quot;/static/arch.04060307.svg&quot; class=&quot;image-center&quot; alt=&quot;Istio Service Mesh Architecture&quot;/&gt;&lt;h4&gt; Envoy &lt;/h4&gt;&lt;p&gt; The data plane of Istio consists of the Envoy sidecar proxy. Envoy is an edge and service proxy that is open source and free that aids in separating network concerns from core applications. Applications don&amp;#x27;t care about the network topology; they just transmit and receive messages to and from localhost. Envoy is fundamentally a network proxy that operates at the OSI model&amp;#x27;s L3 and L4 layers. It operates by processing connections through a series of pluggable network filters. Envoy additionally provides support for an extra L7 layer filter for HTTP-based traffic. Envoy also offers excellent support for the HTTP/2 and gRPC transports. &lt;/p&gt;&lt;p&gt; Many of the features provided by Istio such as security, traffic control, network resiliency are possible due to Envoy. &lt;/p&gt;&lt;h4&gt; Istiod &lt;/h4&gt;&lt;p&gt; Service discovery, configuration, and certificate management are offered by Istiod. &lt;/p&gt;&lt;p&gt; High level routing rules that govern traffic behavior are transformed into Envoy-specific configurations by Istiod and propagated to the sidecars during runtime. Any sidecar that complies with the Envoy API can use Pilot, which synthesizes platform-specific service discovery techniques into an abstract form. &lt;/p&gt;&lt;p&gt; Istio can handle discovery in a variety of settings, including Kubernetes or virtual machines. &lt;/p&gt;&lt;p&gt; To exert finer control over the traffic in your service mesh, you can ask Istiod to modify the Envoy configuration using the Traffic Management API. &lt;/p&gt;&lt;p&gt; Strong service-to-service and end-user authentication are made possible by Istiod security&amp;#x27;s integrated identity and credential management. Istio can be used to enhance unencrypted service mesh traffic. &lt;/p&gt;&lt;p&gt; Operators can enforce regulations with Istio based on service identity rather than on layer 3 or layer 4 network IDs, which are more prone to instability. Additionally, you can limit who has access to your services by using Istio&amp;#x27;s authorisation capability. &lt;/p&gt;&lt;p&gt; In order to enable secure mTLS connection in the data plane, Istiod performs the role of a Certificate Authority (CA) and issues certificates. &lt;/p&gt;&lt;h3&gt; Features &lt;/h3&gt;&lt;h4&gt; Traffic Management &lt;/h4&gt;&lt;p&gt; Performance is impacted by traffic routing, both within and across clusters, which improves deployment strategy. You can simply manage the flow of traffic and API requests between services using Istio&amp;#x27;s traffic routing rules. Istio makes it simple to configure critical activities like A/B testing, canary deployments, and staged rollouts with percentage-based traffic divides, as well as service-level attributes like circuit breakers, timeouts, and retries. &lt;/p&gt;&lt;h4&gt; Observability &lt;/h4&gt;&lt;p&gt; It becomes harder to comprehend behaviour and performance as services become more complicated. Istio produces comprehensive telemetry for each communication taking place within a service mesh. This telemetry makes service activity observable, enabling operators to maintain, optimise, and debug their applications. Even better, you can implement practically all of this instrumentation without making any changes to your applications. Operators are able to fully comprehend how the monitored services are communicating with Istio. &lt;/p&gt;&lt;p&gt; Detailed metrics, distributed traces, and complete access logs are all included in Istio&amp;#x27;s telemetry. You get complete and thorough service mesh observability with Istio. &lt;/p&gt;&lt;h4&gt; Security Capabilities &lt;/h4&gt;&lt;p&gt; Particular security requirements for microservices include defense against man-in-the-middle attacks, adaptable access rules, auditing tools, and mutual TLS. Istio comes with a comprehensive security solution that enables administrators to handle each of these problems. To safeguard your services and data, it offers strong identity, strong policy, transparent TLS encryption, and authentication, authorization, and audit (AAA) tools. &lt;/p&gt;&lt;p&gt; The security architecture used by Istio is built on security-by-default, and it aims to provide in-depth defense so you may deploy security-conscious apps even across networks with a low level of trust. &lt;/p&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[The Ultimate List of Open Source Cloud-Native Tools]]></title><link>https://layer5.io/company/news/the-ultimate-list-of-open-source-cloud-native-tools</link><guid isPermaLink="false">https://layer5.io/company/news/the-ultimate-list-of-open-source-cloud-native-tools</guid><dc:creator><![CDATA[Bill Doerrfeld]]></dc:creator><pubDate>Mon, 29 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/d933bb2908d2076307a5899a5cb48295/tools.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Newsstyle__NewsWrapper-sc-12r6uiw-0 DQvaY&quot;&gt;&lt;div class=&quot;test&quot;&gt;&lt;p&gt;There are so many great open source cloud-native tools for nearly everything you want to do.
And they’re all in one place—look no further than the Cloud Native Computing Foundation (CNCF).This Linux Foundation body has become a locus of some stellar cloud-native open source projects. The CNCF now hosts an array of helpful packages, spanning container scheduling, observability, persistent storage, container runtime and other areas.&lt;/p&gt;&lt;p&gt;Odds are the cloud-native DevOps tool you need has already been developed—it’s only a matter of finding it. In recent posts, we highlighted many CNCF tools across various areas. Below, we’ll gloss over each category from a birds-eye view. Click each headline for the full rundown, or read below for a summary of the tools in each category.&lt;/p&gt;&lt;h3&gt;Scheduling  Orchestration&lt;/h3&gt;&lt;br/&gt;Kubernetes is the most popular container scheduling tool. It can be used to automate the deployment and management of multi-cloud applications. Other scheduling and orchestration utilities from CNCF include Crossplane, Fluid, Karmada, kube-rs, Open Cluster Management and Volcano.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Observability and Analysis&lt;/h3&gt;&lt;br/&gt;Prometheus tops the list of observability and analysis tools. The platform can be used to power your monitoring and alerting systems with fine-grained metrics and excellent querying capabilities. Other CNCF tools for observability and analysis include Jaeger, Fluentd, Thanos, Cortex and OpenTelemetry.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Security and Compliance&lt;/h3&gt;&lt;br/&gt;Open Policy Agent (OPA) can be used to unify cloud-native policies across the cloud-native stack. OPA uses a common language to express authorization policies and provides a policy engine to make authorization decisions. Other CNCF projects that deliver security-as-code include The Update Framework (TUF), Falco, Notary, cert-manager and Curiefense.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;CI/CD&lt;/h3&gt;&lt;br/&gt;Argo is a suite of packages that help direct jobs on Kubernetes to aid a continuous delivery pipeline. Using Argo, developers can create multi-step custom workflows and share these workflows across a cluster. Other CI/CD tools hosted by CNCF include Flux, Brigade, Keptn, OpenGitOps and OpenKruise.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Service Mesh Tools&lt;/h3&gt;&lt;br/&gt;Linkerd is a highly performant developer-favorite service mesh comprised of a control plane to apply configurations and a data plane that deploys its own unique proxy. This proxy can apply consistent security, observability, monitoring and telemetry features across distributed microservices. Other service mesh tools from CNCF include Kuma, Open Service Mesh (OSM), &lt;a href=&quot;/projects/service-mesh-interface-conformance&quot;&gt;Service Mesh Interface (SMI) &lt;/a&gt; , &lt;a href=&quot;/meshery&quot;&gt;Meshery&lt;/a&gt; and &lt;a href=&quot;/projects/cloud-native-performance&quot;&gt;Service Mesh Performance(SMP)&lt;/a&gt;.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Service Proxies&lt;/h3&gt;&lt;br/&gt;Envoy is a service proxy commonly used within service meshes like Istio and Kuma. Envoy is intended to run alongside applications to help standardize networking and observability within large microservices networks. Other service proxy projects include Contour BFE and OpenELB.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Persistent Storage&lt;/h3&gt;&lt;br/&gt;Rook is a tool that helps automate away some of the pains of managing cloud-native persistent storage. Rook supports file, block and object storage types and can be used for programmatic storage, migration, disaster recovery, monitoring and resource management. Other cloud-native persistent storage projects include Longhorn, CubeFS, K8up, OpenEBS, ORAS, Piraeus Datastore and Vineyard.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Cloud-Native Database Tools&lt;/h3&gt;&lt;br/&gt;TiKV is a unified distributed storage layer that can process large amounts of data. The project supports a key-value API and has rapid response times. Other cloud-native database utilities include Vitess, a clustering system for horizontal scaling of MySQL and SchemaHero, a Kubernetes operator for declarative database schema management.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Container Runtime&lt;/h3&gt;&lt;br/&gt;Containerd is an industry-standard container runtime supported by most container-based systems. Originally built as part of Docker, containerd was donated to the Linux Foundation in 2015. Other notable CNCF container runtime utilities include CRI-O, Inclavare Containers and WasmEdge Runtime.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;App Definition and Build Tools&lt;/h3&gt;&lt;br/&gt;Helm is a prevalent Kubernetes package manager widely used to share a manifest of dependencies. Operators often use Helm charts to find and install third-party applications. Other notable tools which help address operational concerns of Kubernetes include Buildpacks, KubeVirt, Operator Framework and Backstage.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Cloud-Native Networking&lt;/h3&gt;&lt;br/&gt;Cilium is a tool that brings eBPF-based networking, security and observability. Cilium helps build out networking between container workloads and cross-cluster connectivity. Additional cloud-native networking utilities include Antrea, CNI-Genie, Kube-OVN, Network Service Mesh (NSM) and Submariner. There’s also the Container Network Interface (CNI), an interface specification for container networking.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Streaming and Messaging&lt;/h3&gt;&lt;br/&gt;CloudEvents offers a specification intended to help standardize the event-based communication from various event publisher systems. By having a way to describe events consistently, developers could solve interoperability issues. Other CNCF streaming and messaging projects include NATS, Pravega, Strimzi and Tremor.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Chaos Engineering&lt;/h3&gt;&lt;br/&gt;Chaos Mesh is a chaos engineering platform for Kubernetes. Using Chaos Mesh, operators can push their Kubernetes deployments to the limit with stress testing, fault injections, and other testing behaviors. You can also schedule routine tests. Other cloud-native chaos testing tools from CNCF include Litmus and ChaosBlade.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Key Management&lt;/h3&gt;&lt;br/&gt;SPIFFE is defined as a universal identity control plane for a distributed architecture. Using SPIFFE, engineers can quickly construct a standard method to identify workloads and automatically secure service-to-service communication. SPIRE is the product-ready reference implementation of SPIFFE. Other key management tools from CNCF include Athenz and Teller.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;Edge Computing and Bare Metal&lt;/h3&gt;&lt;br/&gt;KubeEdge helps extend cloud-native capabilities into edge computing. It’s specifically designed with the constraints of edge nodes in mind, such as reliability and resource limitations. Other projects that help extend Kubernetes to the edge include Akri, OpenYurt and SuperEdge. Other tools aid in provisioning K8s on bare metal, such as Metal3.io and Tinkerbell.&lt;br/&gt; &lt;br/&gt;&lt;h3&gt;The Forecast Looks Cloud-Native&lt;/h3&gt;&lt;br/&gt;By 2023, the &lt;a href=&quot;https://containerjournal.com/features/majority-of-apps-will-use-cloud-native-development-by-2023/&quot;&gt;majority of applications will be cloud-native&lt;/a&gt;. The cloud-native world is here to stay, and open source is the foundation to support our new era of microservices, containerization and DevOps.&lt;p&gt;Although you could technically self-host your way through development and operations using these open source projects, organizations will most likely adopt a blend of open source, proprietary and as-a-service cloud offerings to get the job done. Regardless, it’s cool to know what’s available for free use.&lt;/p&gt;&lt;p&gt;It should also be mentioned that tools change from time to time. As such, you can always view the up-to-date CNCF landscape here. Stay tuned as we keep an eye on CNCF and related bodies that continue to carry the cloud-native torch forward!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[DevOps Adoption: Identifying the Right Metrics]]></title><link>https://layer5.io/resources/devops/devops-adoption-identifying-the-right-metrics</link><guid isPermaLink="false">https://layer5.io/resources/devops/devops-adoption-identifying-the-right-metrics</guid><pubDate>Tue, 23 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/eba4e5898081df468c1c4288ce73623d/devops-adoption.webp" length="0" type="image/webp"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt;According to Puppet’s State of DevOps Report 2021, 83% of IT professionals report that their organizations have previously implemented DevOps practices or are doing so right now to unlock higher business value, achieve faster time to delivery, and boost security of systems.&lt;/p&gt;&lt;p&gt;However, DevOps teams from many industries frequently struggle to identify the right metrics to monitor and measure success. In this &lt;a href=&quot;/static/devops-adoption-choosing-the-right-metrics-a064d95e7d0e37af18817d28b58ef4ff.pdf&quot;&gt;infographic&lt;/a&gt;, we highlight the metrics all DevOps professionals should measure to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Identify places in the pipeline to speed up deployments.&lt;/li&gt;&lt;li&gt;Make data-driven decisions to improve the deployment process.&lt;/li&gt;&lt;li&gt;Analyze the speed at which products are reaching the market in comparison to competitors.&lt;/li&gt;&lt;/ul&gt;&lt;h3 style=&quot;margin-top:1rem&quot;&gt;Monitor these 5 metrics to understand how to speed up your DevOps toolchain:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Deployment Time&lt;/li&gt;&lt;li&gt;Change Failure Rate&lt;/li&gt;&lt;li&gt;Recovery Time&lt;/li&gt;&lt;li&gt;Release Cadence&lt;/li&gt;&lt;li&gt;Lead Time&lt;/li&gt;&lt;/ul&gt;&lt;a href=&quot;/static/devops-adoption-choosing-the-right-metrics-a064d95e7d0e37af18817d28b58ef4ff.pdf&quot;&gt;&lt;img src=&quot;/static/devops-adoption-a44cb4bc65c93dfa8fa404e38f05233a.webp&quot; alt=&quot;Right metrics for adopting DevOps&quot;/&gt;&lt;/a&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[What is GitOps?]]></title><link>https://layer5.io/resources/cloud-native/what-is-gitops</link><guid isPermaLink="false">https://layer5.io/resources/cloud-native/what-is-gitops</guid><pubDate>Tue, 16 Aug 2022 00:00:00 GMT</pubDate><enclosure url="https://layer5.io/static/a8d747801f0e266dbc9bb2b192cd3dc1/github-dark.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;div class=&quot;Resourcesstyle__ResourcesWrapper-sc-1y33ukx-0 hKxBLf&quot;&gt;&lt;p&gt;GitOps revolves around the central notion that infrastructure can be treated as code. It is an operational framework that incorporates DevOps best practices for infrastructure automation, including version control, collaboration, compliance, and CI/CD tooling, which are often used for application development. Like code, not only can you store your infrastructure configuration in a source code version system, but you can also take your infrastructure configuration and any changes to its configuration through the same change management process that you do when updating your applications and services. In part, GitOps is about change management, and consequently, it is about risk reduction and risk management. When you automate a process and classify the manner in which you systemize the process, risk is reduced through the consistency and series of processes and reviews changes go through.&lt;/p&gt;&lt;p&gt;GitOps is the acknowledgement that declarative systems that everything is (or should be) defined as code. With all code in a source code system, that system becomes the source of truth and in the system of record for how your infrastructure is running. Well, that is, assuming that your infrastructure configuration hasn&amp;#x27;t drifted from its desired state defined in your source code system. If Git is the source of truth, you cannot run operations manually by executing random commands. Doing so would mean that Git would stop being the only source of truth. Instead, the only goal of operations is to define the desired state as code and store it in git. Then, let the machines synchronize that with the actual state. Such synchronization must be continuous so that the two states are (almost) always in sync. In other words, GitOps is about defining everything as code, storing that code in Git, and letting the machines detect the drift between the desired and the actual state – and making sure that drifts are resolved as soon as possible, hence resulting in the two states being almost always in sync.&lt;/p&gt;&lt;h2&gt; Principles of GitOps&lt;/h2&gt;&lt;h3&gt; 1) Declarative&lt;/h3&gt;&lt;p&gt; According to this principle, the entire system should have a declarative description. Let us first understand what a system description is. What is committed to your Git repository is called the System Description. One or more files that define each system component and its state will be included in the system description. According to GitOps, the way in which we store those definitions is crucial, and we must do so declaratively. That implies that the description of our system will be saved as data.&lt;/p&gt;&lt;p&gt; In the declarative approach, we specify how we want the system to look not how we can achieve that state. If we want to make any changes, we change the description instead of the series of steps to get there. Declarative configuration is critical for GitOps because it provides a description of the system that an automated agent can understand and utilize to take action.&lt;/p&gt;&lt;h3&gt; 2) Single Source of Truth&lt;/h3&gt;&lt;p&gt; The second principle mandates that we keep that system description inside of Git. Therefore, we decide to maintain the official blueprints, which outline the ideal system state version in Git. A git commit is required if we wish to modify the blueprint. The blueprint can also be called the desired state. This helps developers, testers, operations, security, and automations to have a single reference and keep uniformity in everyone’s vision.&lt;/p&gt;&lt;p&gt; GitOps also improves a system&amp;#x27;s ability to recover from failure because it&amp;#x27;s simple to roll back an unsuccessful change or restore the entire system from the repository.&lt;/p&gt;&lt;h3&gt; 3) Automated Change Delivery&lt;/h3&gt;&lt;p&gt; Only automation allows us to apply modifications made to the blueprint to systems already in operation. Delivery of changes is entirely automatic. GitOps doesn&amp;#x27;t allow manual editing. Because standard workflows only need GitHub, which is such a well-known platform, automation enables changes to be delivered through simpler for developers to use workflows. Additionally, automation standardizes your delivery processes, improving the predictability and consistency of system operations.&lt;/p&gt;&lt;h3&gt; 4) Automated State Control&lt;/h3&gt;&lt;p&gt; The fourth principle uses automation to keep our operating system in alignment with the desired state. Drift is the deviation of the runtime state of our system from the desired state. The system&amp;#x27;s blueprints and what is actually operating in the system don&amp;#x27;t match. Therefore, if the operating system drifts from what we have specified in Git, an operator will restore it by bringing it back to the intended condition.&lt;/p&gt;&lt;h2&gt; Benefits of GitOps&lt;/h2&gt;&lt;h3&gt; 1) Improves compliance and security:&lt;/h3&gt;&lt;p&gt; Since teams use a single platform for infrastructure management, a streamlined toolchain reduces attack surfaces. Teams can use the version control system to roll back to a desired state in the event of an assault. GitOps lessens outages and downtime as a result, allowing teams to continue working on projects in a secure environment.&lt;/p&gt;&lt;h3&gt; 2) Boosts productivity and cooperation:&lt;/h3&gt;&lt;p&gt; GitOps includes CI/CD pipelines, Git workflows, and infrastructure as code best practices for software development. These prerequisite tools, knowledge, and skill sets are already present in operations teams, thus adopting GitOps won&amp;#x27;t need a steep learning curve. GitOps workflows streamline procedures in order to improve visibility, establish a single source of truth, and have a small number of tools on hand.&lt;/p&gt;&lt;h3&gt; 3) Automation enhances developer efficiency and lowers costs:&lt;/h3&gt;&lt;p&gt; Productivity rises with CI/CD tooling and continuous deployment since teams can concentrate on development rather than laboriously manual processes thanks to automation. Since team members can use any language and tools they like before pushing updates to GitHub, GitOps workflows enhance the developer experience. Infrastructure automation increases output and decreases downtime while enabling better cloud resource management, which can also save costs.&lt;/p&gt;&lt;h3&gt; 4) Increases stability and reliability:&lt;/h3&gt;&lt;p&gt; Human mistake is decreased through infrastructure that is codified and repeatable. Code reviews and collaboration are made easier by merge requests, which also assist teams in finding and fixing issues before they are released to the public. Additionally, there is less risk because all infrastructure changes are tracked through merge requests and may be undone if an iteration is unsuccessful. By allowing rollbacks to a more stable state and providing distributed backup copies in the event of a significant outage, Git processes speed up recovery time. GitOps gives teams the freedom to iterate more quickly and release new features without worrying about creating an unstable environment.&lt;/p&gt;&lt;h3&gt; 5) Faster development and deployment:&lt;/h3&gt;&lt;p&gt; GitOps provides quicker and more frequent deployments, making it easier for teams to make a minimum viable change. Teams can ship many times per day and roll back changes if there is a problem by utilizing GitOps best practices. Team members can offer business and customer value more quickly thanks to high velocity deployments. Teams are more flexible and able to react to customer needs more quickly with continuous integration.&lt;/p&gt;&lt;h2&gt; Key Components of a GitOps workflow&lt;/h2&gt;&lt;p&gt; To summarize, the following are the four components we require to a GitOps workflow:&lt;/p&gt;&lt;ol&gt;&lt;li&gt; Git repository: The code and configuration of the application are verified there. &lt;/li&gt;&lt;li&gt; CD pipeline: It is responsible for building, testing, and deploying the application. &lt;/li&gt;&lt;li&gt; Application deployment tool: It is employed to manage the target environment&amp;#x27;s application resources. &lt;/li&gt;&lt;li&gt; Monitoring system: It keeps tabs on the performance of the application and gives the development team feedback. &lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item></channel></rss>